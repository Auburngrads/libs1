---
title: "`r SMRD:::info('book')`"
subtitle: "`r SMRD:::info('chapter4')`"
author: "`r SMRD:::info('authors')`"
date: "`r format(Sys.Date(), '%d %B %Y')`"
footer: "`r paste('SMRD: ', SMRD:::info('chapter4'))`"
output:
  slidy_presentation:
    smart: false
    fig_caption: yes
graphics: yes
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
source('../scripts/R/setup.R')
root_url <- 'https://afit.shinyapps.io/'
```

# OVERVIEW

```{r echo=FALSE, message=FALSE, warning=FALSE}
shiny::includeCSS('../scripts/css/flatslidy.css')
shiny::includeScript("../scripts/js/jquery.min.js")
shiny::includeScript("../scripts/js/jkf-scroll.js")
```

## This Chapter Explains...

- Important ideas behind parametric models in the analysis of reliability data

- Motivation for important functions of model parameters that are of interest in reliability studies

- The location-scale family of probability distributions

- Properties and importance of the exponential distribution 

- Properties and importance of the log-location-scale distributons such as the Weibull, lognormal, and loglogistic distributions

- How to generate pseudorandom data from a specified distribition (such random data are used in simulation evaluations in subsequent chapters)

# 4.1 - INTRODUCTION

## Parametric Models For Reliability Data

- Can simplify the process of computing quantities of interest

- Complement nonparametric techniques and provide a few advantages

- Parametric models can be described concisely, by listing a few parameters rather that the entire curve

- Parametric models enable usage extrapolation in the upper or lower tails of the distribution

- Parametric models provide smooth estimates of failure-time distributions

- Parametric and nonparametric techniques should both be used to analyze a data set

# 4.2 - QUANTITIES OF INTEREST IN RELIABILITY APPLICATIONS

The quantities of interest in most reliability applications will be functions of the parameters $\theta$

- The CDF $\rightarrow F(t|\theta)$ 

    + Failure probability for a single unit at or before time $t$
    
    + Fraction of units from a population that have failed at or before time $t$

- The quantile value $\rightarrow t_{p}=F^{-1}(p|\theta)$

    + Time at which the failure probability for a single unit is $p$
    
    + Time at which $p$ units are likely to have failed 

- The hazard function $\rightarrow h(t|\theta)=f(t|\theta)/S(t|\theta)$

    + Conditional failure probability in the interval $[t, t+\Delta t)$
    
    + Time at which $p$ units are likely to have failed

- The mean lifetime $\;\;\;\;\;\;\hspace{1pt}\rightarrow \; E[T]=\int_{0}^{\infty}tf(t|\theta)dt=MTTF$

- The lifetime variance $\;\;\;\rightarrow \; Var[T]=\int_{0}^{\infty}\left(t-E[T]\right)^{2}f(t|\theta)dt$

# 4.3 - LOCATION-SCALE AND LOG-LOCATION-SCALE DISTRIBUTIONS

## The Location-Scale Family of Distributions

```{r, out.width='100%'}
knitr::include_app(paste0(root_url,'location_scale'), height = '800px')
```

## The Log-Location-Scale Family of Distributions

```{r, out.width='100%'}
knitr::include_app(paste0(root_url,'log_location_scale'), height = '800px')
```

# 4.13 - Generating Psuedorandom Observations From a Specified Distribution

- R generates pseudorandom observations using, (for example)

    + `rnorm(n,0,1)` which generates $n$ random observations from a $NOR(0,1)$ distribution 

    + <red>But how does this work?</red>

## Types of Psuedorandom Number Generators

- Several algorithms exist to generate PRN's

- These algorithms are classified by

    + "Randomness" (cryptography requires numbers that are more random)

    + Periodicity (related to randomness)

    + Speed (time required to generate 1 million PRN's) 

- Specific 'brands' of PRNG

    + Linear Congruential

    + Combined Linear Congruential

    + Inversive Linear Congruential

    + Multiply-With-Carry

    + Lehman

    + [Mersenne Twister](https://en.wikipedia.org/wiki/Mersenne_Twister) <red>(the default PRNG in R, C, MatLab, Python, Julia,...)</red>

## PRNG Seed Values

- PRNG's require a seed value to establish how the random numbers will be generated

- The function `set.seed( )` can be used to set the seed values in R

- Setting the seed value allows you to create 'repeatable' random numbers <red>Is that an oxymoron?</red>

- <focus>Why would anyone want repeatable random numbers?</focus>

- I often use randomly generated data to discuss an example

- The matrix $\bar{A}$ below is one example of this

$$\bar{A}=\left[`r xarray(matrix(round(sample(1:50, size = 16), digits = 0), nrow = 4), matrix = T, digits = c(0,0,0,0,0))`\right]$$

- If I say 'the diagonal elements in $\bar{A}$ are $30,12,31,16$' it would be confising if the actual elements were different

- By setting the seed value I know what values will be generated

$$\bar{A} = \left[`r set.seed(4);xarray(matrix(round(sample(1:50, size = 16), digits = 0), nrow = 4), matrix = T, digits = c(0,0,0,0,0))`\right]$$

<div class='example'>
### Example - Generating PRN's in R

## Let's generate 4 sets of PRN With and Without Seed Values

1) Eight observations from a $NOR(0.75, 1.5)$ distribution `set.seed(NULL)`

```{r, results='hide'}
set.seed(NULL)
set1 <- sort(round(rlnorm(8, 0.75, 1.5), digits = 4))
```

2) Eight observations from a $NOR(0.75, 1.5)$ distribution `set.seed(NULL)`

```{r, results='hide'}
set.seed(NULL)
set2 <- sort(round(rlnorm(8, 0.75, 1.5), digits = 4))
```

3) Eight observations from a $NOR(0.75, 1.5)$ distribution `set.seed(42)`
```{r, results='hide'}
set.seed(42)
set3 <- sort(round(rlnorm(8, 0.75, 1.5), digits = 4))
```

4) Eight observations from a $NOR(0.75, 1.5)$ distribution `set.seed(42)`
```{r, results='hide'}
set.seed(42)
set4 <- sort(round(rlnorm(8, 0.75, 1.5), digits = 4))
```

## What Does This Show?

- The table below shows the four sets of PRN's that were generated above

    + The observations in Set 1 and Set 2 are different because no seed value was set

    + The observations in Set 3 and Set 4 are the same because they were generated using the same seed value

```{r, echo=FALSE}
tab <- data.frame(set1,set2,set3,set4)
knitr::kable(tab, col.names = NA, format = 'markdown')
```
</div>

## Pseudorandom Numbers From Continuous Distributions

- R simulates observations from contiuous distributions in the following way

    1) Create a vector of observations from a $UNIF(0,1)$ distribution (These observations serve as values for $F(t_p)= p$)

    2) Select a distribution and set of parameter values to simulate from 

    3) Invert the CDF to find the quantile function $t_{p}=F^{-1}(p)$

    4) Substitute the $UNIF(0,1)$ observations for $p$ and the selected parameter values and solve for $t_p$

    5) The resulting values for $t_p$ will be PRN's from the selected distribution

<div class="example">
### Simulate Observations From A $EXP(2)$ Distribution

## Step 1 - Create a vector of observations from a $UNIF(0,1)$

```{r, results='markup'}
probs <- runif(10,0,1)
```

## Step 2 - Select a distribution and parameter values to simulate from

- We already selected the exponential distribution with CDF
$$F(t|\theta)=1-\exp\left[-\frac{t}{\theta}\right]$$

- We already selected the parameter value $\theta=2$ so the CDF for the specific distribution we are simulating from is
$$F(t|\theta=2)=1-\exp\left[-\frac{t}{2}\right]$$

## Step 3 - Invert the CDF to find the quantile function $t_{p}=F^{-1}(p)$

- The quantile function is found by inverting the CDF, solving for $t_p$ 

    + <focus>Not all CDF's can be inverted analytically</focus> 

    + For these distributions we have to solve for $t_p$ numerically

- The quantile function for the exponential distribution we wish to sample from is
$$t_{p}=-\ln[1-p]\times2$$

## Step 4 - Substitute the $UNIF(0,1)$ observations for $p$ and the selected parameter values and solve for $t_p$

- Let's create the exponential quantile function in R for any value of $\theta$
```{r, results='hide'}
t_p.exp <- function(p,theta) -log(1-p)*theta
```

- Substituting the values $p=$`probs` and $\theta=2$ in this function returns $10$ simulated observations from the $EXP(2)$ distribution
```{r, results='markup'}
t_p.exp2 <- t_p.exp(p = probs, theta = 2)
```

## Step 5 - The resulting values for $t_p$ will be PRN's from the selected distribution

- We can compare our simulated values to a plot of the CDF for the $EXP(2)$ distribution

- In this example, only $10$ observations were simulated, so the fit may be poor

- Simulating more observations (say $1000$) would reduce the sampling error and result in a better fit 

```{r, echo=2:4, fig.align='center'}
par(family = "serif", bg = NA)
plot(ecdf(t_p.exp2), main = "")
curve(pexp(x,1/2), add = TRUE, lwd = 2, col = "red")
```
</div>

<div class='example'>
### Generating Psuedorandom Censored Observations

- The probability integral transform provides an efficient way to simulate random observations from many distributions

- However, these observations assume that we have complete data

- Suppose we wanted to generate $n$ _censored_ observations from a distribution $F(t)$

## Pseudorandom Order Statistics

- When planning a test we choose when the test will end beforehand 

    + After a specified time has elapsed

    + After a specified number of failures have been observed



In this instance

- We generate $n$ observations from a $UNIF(0,1)$ distribution 

- Say we know that observation $i-1$ occurs before censoring begins

- What is the probability that observation $i$ also occurs before censoring begins?

- This is accomplished using 

First, let's generate and sort $n$ observations from a $UNIF(0,1)$ distribution

```{r, results='markup'}
dat  <- c(0,sort(runif(10,0,1))) ; dat 
rank <- c(rank(dat)) ; rank
```

- Note that a zero has been added to the vector of observations since $U_{(0)}=0$

- Next, we'll compute the order statistics

```{r, results='markup'}
term1 <- 1-dat[rank[1:length(rank)-1]]

term2 <- 1-dat[rank[2:length(rank)]]

term3 <- 1/((length(rank)-1)-rank[2:length(rank)-1]+1)

order <- 1-(term1)*(term2)^(term3)

order
```
</div> 

### Type-II Censored Pseudorandom Observations

For $n=10$ systems with $r=3$ failures the $UNIF(0,1)$ order statistics are

```{r, results='markup'}
r<-3
term1 <- 1-dat[rank[1:(r+1-1)]]

term2 <- 1-dat[rank[2:(r+1)]]

term3 <- 1/((length(rank)-1)-rank[1:r]+1)

order <- 1-(term1)*(term2)^(term3)

order
```


```{r, results='markup'}
set.seed(42)
censored.samples <- function(n, cen.time = NULL, cen.fails = NULL) {
  
dat  <- c(0,sort(runif(n,0,1))) 
rank <- c(rank(dat)) 

cen.samp <- NULL

for(i in 1:n) {
  
U <- 1-(1-dat[rank[i]])*(1-dat[rank[i+1]])^(1/(n+1-i))

cen.samp <- c(cen.samp,U)

}
return(cen.samp)
}

set.seed(42)
samp1 <- censored.samples(n = 25)
samp2 <- sort(runif(25))
obs1 <- qweibull(samp1, shape = 2.25, scale = 10)
obs2 <- qweibull(samp2, shape = 2.25, scale = 10)
```
