---
title: "`r SMRD:::info('book')`"
subtitle: "`r SMRD:::info('chapter17')`"
author: "`r SMRD:::info('authors')`"
date: "`r format(Sys.Date(), '%d %B %Y')`"
output:
  slidy_presentation:
    smart: false
    fig_caption: yes
footer: "`r paste('SMRD: ', SMRD:::info('chapter17'))`"
runtime: shiny
graphics: yes
---

# CHAPTER OVERVIEW

```{r intro, echo=FALSE,message=FALSE, warning=FALSE}
source('scripts/R/setup.R')
shiny::includeCSS('scripts/css/flat-slidy.css')
shiny::includeScript(path = "scripts/js/audiojs/audiojs/audio.min.js",
                     "audiojs.events.ready(function() {audiojs.createAll();});")
shiny::includeScript("scripts/js/jkf-scroll.js")
```

## Objectives

- Model life as a function of explanatory variables

- Graphical methods for displaying censored regression data

- Time scaling transformation functions and other forms of relationships between life and explanatory variables

- Simple regression models to relate life to explanatory variables

- Likelihood methods to draw conclusions from censored regression data

- How to detect departures from an assumed regression model

- Extensions to more elaborate nonstandard regression models that can be used to relate life to explanatory variables, including quadratic regression, models in which $\sigma$ depends on explanatory variables, and proportional hazards models

## Overview

# 17.1 - INTRODUCTION

## Failure Data w/o Explanatory Variables (Chapters 3 - 11)

- The methods presented in these chapters assumed that an underlying failure process could be modeled with a single distribution

- This assumption might not be true if: 

    + Items in a population were exposed to different use rates

    + Items in a population were exposed to different environments

- Observe the probability plot below

    + Starting at $t = 700$ hours, $F(t)$ increases sharply - what might this mean?

    + It could mean that the failure process changed (i.e. a second failure mode was exposed at $700$ hours)

    + It could also mean that the data were observed from systems exposed to different conditions and should not have been lumped together

    + It should be easy to determine what's happening by looking at the data<br/><focus>If this information was captured</focus>

```{r}
teachingApps::includeApp('bent_probplot')
```

## Failure data with explanatory variables (Chapters 17 - 20)

- These chapters present methods to model data observed from systems exposed to different conditions 

- Differing usage conditions are specified by explanatory variables $\displaystyle \mathbf{x}=x_{i},...x_{k}$

- The probability of failure is then a function of time and the severity of the usage condition $F(t|\theta = g(x_{i},...x_{k}))$

- In the literature, explanatory varibles may be called 

    + Regressors

    + Factors

    + Stressors (I prefer this term in a reliability context)

- Systems may be exposed to several <u>__stressors__</u> simultaneously

- For example, a home's roofing system is exposed to many stressors

    + Temperature

    + Humidity

    + UV exposure

    + Physical loads (snow, wind)

- The specific measure of a stressor is the <u>__stress level__</u>

    + Degrees (Celsius/Kelvin/Farenheit/Rankine)

    + $\% RH$

    + Pascals (Pa), Newtons (N), Pound-force (lb)

- The combination of stress levels to which a system is exposed is called the <u>__stress state__</u>

## Example 17.1 - Computer Program Execution Time `comptime`

<div class='example'>
## Example 17.2 - Nelson's Superalloy Data Set

```{r, eval=FALSE}
teachingApps:::superalloy_data17()
```
</div>

# 17.2 - FAILURE TIME REGRESSION MODELS

- The method of modeling time to failure as a function of explanatory variables is known as failure time regression

- The primary goal of failure-time regression is to...

    + ...estimate product life at a "use-level" stress state...
    
    + ...using data observed at one or more "accelerated" stress states.

- A secondary goal of failure time regression is to estimate product life at one or more stress states to perform trade-offs when establishing the specifications

    + Statements such as "...do not store above $100^o F$..."
    
    + Expiration dates on foods (depends on Fridge temperature setting)


# 17.2.1 - Parameters as Functions of $\underline{x}=x_1,...,x_n$


An important class of regression models assumes one (or more) values of $\underline{\theta}$ to be linearly dependent on the stress state

- <font color="blue">__OLS regression__</font> $\rightarrow \mu=\beta_0+\beta_i\mathbf{x_i}$

Additional classes of regression models assume some $f(\underline{\theta})$ to be linearly dependent on the stress state

- <font color="red">__Scale accelerated failure time model__</font> $\rightarrow t_p$ 

- <font color="green">__Proportional hazards model__</font> $\rightarrow h(t)$

Failure-time regression includes each of these classes of models

# 17.2.2 - The Scale-Accelerated Failure Time Model


Often called the <u>Accelerated Failure Time model</u> in the literature

Used to describe the effect that explanatory variables have on how quickly life is consumed

Assumes a multiplicative acceleraction factor defined as

$$\frac{1}{\mathcal{AF}(\mathbf{x})}=\frac{T(\mathbf{x})}{T(\mathbf{x_0})},\;\mathcal{AF}(\mathbf{x})>0$$

where

- $T(\mathbf{x_0})\equiv$ usage (time, distance, etc.) at some baseline stress state $\mathbf{x_0}$
- $T(\mathbf{x})\;\;\equiv$ usage (time, distance, etc.) at some stress state $\mathbf{x}\ne\mathbf{x_0}$

It follows from this definition that

$$
\begin{aligned}
S\left(t|\mathcal{AF}(\mathbf{x})\right)&=S_0\left(\mathcal{AF}(\mathbf{x})\times t\right)\\\\\\
f\left(t|\mathcal{AF}(\mathbf{x})\right)&=\mathcal{AF}(\mathbf{x})\times f_0\left(\mathcal{AF}(\mathbf{x})\times t\right)\\\\\\
\lambda\left(t|\mathcal{AF}(\mathbf{x})\right)&=f\left(t|\mathcal{AF}(\mathbf{x})\right)/S\left(t|\mathcal{AF}(\mathbf{x})\right)\\\\\\
&=\mathcal{AF}(\mathbf{x})\times\lambda_0\left(\mathcal{AF}(\mathbf{x})\times t\right)
\end{aligned}
$$

The value of $\mathcal{AF}(\mathbf{x})$ <font color="red">accelerates</font>/<font color="blue">decelerates</font> time in the sense that 

- Time moves more <font color="red">quickly</font>/<font color="blue">slowly</font> at $\mathbf{x}$ than at $\mathbf{x_0}\;\;\;\;\;\;\;$ (Figure 17.3)

- The cdf is shifted <font color="red">left</font>/<font color="blue">right</font> by <font color="red">$\mathcal{AF}(\mathbf{x})$</font>/<font color="blue">$(1/\mathcal{AF}(\mathbf{x}))\;\;$</font> (Figure 17.4)

## Figure 17.3 - SAFT Models Illustration

```{r, echo=FALSE, fig.align='center', fig.height=5.25}
par(family  = "serif", mar = c(4.5,4.5,1,2.1))
curve(1*x, xlim = c(0,3), ylim = c(0,3), 
      xlab = parse(text = "Time~at~level~x[0]"),
      ylab = parse(text = "Time~at~level~x"),
      las = 1, cex.axis = 1.1, cex.lab = 1.1, lwd = 2)
curve(3*x, lwd = 2, add = TRUE, col = "blue")
curve(x/3, lwd = 2, add = TRUE, col = "red")
text(x = .225,
     y = 2.5,
     labels = 'Scale\nDecelerating\nTransformation', 
     adj = 0, 
     cex = 1.1)
text(x = 2.0,
     y = 1.05,"Scale\nAccelerating\nTransformation", 
     adj = 0, 
     cex = 1.1)
legend('bottomright',
       legend = c(expression(AF(x) == 1/3),
                  expression(AF(x) == 3)),
       lwd = 2,
       col = c('blue','red'),
       bty = 'n')
```

## Figure 17.4 - SAFT Models Illustration


```{r, echo=FALSE, fig.align='center', fig.height=5.25}
par(bg = NA, family  = "serif", mar = c(4.5,4.5,0,2.1))
curve(plnorm(x, meanlog = 1, sdlog = 2), xlim = c(1,1000), log = "xy",
      xlab = parse(text = "Time~(t)"),
      ylab = parse(text = "Probability~F(t)"),
      las = 1, cex.axis = 1.1, cex.lab = 1.1, lwd = 2)
curve(plnorm(3*x, meanlog = 1, sdlog = 2), lwd = 2, add = TRUE, col = "red")
curve(plnorm(x/3, meanlog = 1, sdlog = 2), lwd = 2, add = TRUE, col = "blue")
legend("bottomright", 
       c(parse(text = "italic(AF)(bold(x))==3"),
         parse(text = "italic(AF)(bold(x))==1"),
         parse(text = "italic(AF)(bold(x))==1/3")),
       bty = "n", lwd = 2, col = c("red","black","blue"), cex = 1.1)
```

How can the effects of multiple stressors be combined into a single $\mathcal{AF}$ value? 

- For stress state $\mathbf{x}=x_1,...,x_k,$ a commonly-used mathematical form is

$$\mathcal{AF}(\mathbf{x})=1/\exp[\beta_1x_1+\cdots+\beta_kx_k]$$

Substituting this expression into the original definition, (Equation 17.1) rearranging, and taking logs gives

$$
\begin{aligned}
\log[T(\mathbf{x})]&=-\log[\mathcal{AF}(\mathbf{x})]+\log[T(\mathbf{x_0})]\\\\\\
\log[T(\mathbf{x})]&=-\beta_1x_1-\cdots-\beta_kx_k+\epsilon
\end{aligned}
$$

# 17.3 - SIMPLE LINEAR REGRESSION MODELS

# 17.3.1 - Location-Scale Regression Model and Likelihood


For stress state $\mathbf{x}=x$ the location-scale failure time regression model is

$$P(Y\le y)=F(y|\mu, \sigma)=\Phi_{(\cdot)}\left(\frac{y-\mu}{\sigma}\right)$$

Where

- $\mu=\beta_0+\beta_1 x$
- $\sigma$ is not a function of $\mathbf{x}$ 

and

$$y_p(\mathbf{x})=\mu+\Phi^{-1}_{(\cdot)}(p)\sigma=\beta_0+\beta_1 x+\Phi^{-1}_{(\cdot)}(p)\sigma$$

For $n$ independent observations with "exact" failure times and right censoring

$$
\begin{aligned}
\mathcal{L}(\beta_0,\beta_i,\sigma)&=\prod_{i=1}^n\mathcal{L}_i(\beta_0,\beta_1,\sigma|data_i)\\
&=\prod_{i=1}^n\left[\frac{1}{\sigma}\phi_{(\cdot)}\left(\frac{y_i-\mu_i}{\sigma}\right)\right]^{\delta_i}\left[1-\Phi_{(\cdot)}\left(\frac{y_i-\mu_i}{\sigma}\right)\right]^{1-\delta_i}
\end{aligned}
$$

where

- $\mu_i=\beta_0+\beta_1 x$
- $\delta_i=\begin{cases}1&\mbox{for an "exact" failure time}\\0 &\mbox{for a right censored observation}\end{cases}$

In some circumstances closed form solutions exist to compute $\hat{\beta_0}_{_{MLE}},\hat{\beta_1}_{_{MLE}},\hat{\sigma}_{_{MLE}}$

- Normally distributed errors

- Constant variance

- Complete data

For reliability data, the presence of censoring precludes closed form solutions

- ML is a more robust method for estimating parameters than the normal equations used in least squares estimation 

# 17.3.2 - Log-Location-Scale Regression Model and Likelihood


# 17.4 - STANDARD ERRORS AND CONFIDENCE INTERVALS FOR REGRESSION MODELS

# 17.4.1 - Standard Errors and CIs for Parameters

Appendix B6.7 describes the general theory for computing CI's for regression model parameters 

- Based on the large sample approximate normal distribution of the ML estimates for

$$\hat{\mathbf{\theta}}=\left(\hat{\beta_0}, \hat{\beta_1}, \hat{\sigma}\right)$$

- The local estimate for the covariance matrix is the inverse of the observed information matrix computed at $\hat{\mathbf{\theta}}$

$$\hat{\Sigma}_{\hat{\theta}}= -\mathcal{I}_{\hat{\mathbf{\theta}}}^{-1}=-\left[\frac{\partial^2\mathcal{L}}{\partial\mathbf{\theta}^2}\right]^{-1}$$

$$
\begin{aligned}
\hat{\Sigma}_{\hat{\theta}}&=\left[\begin{array}{lll}
\widehat{Var}(\hat{\beta}_0)& 
\widehat{Cov}(\hat{\beta}_0,\hat{\beta}_1)&
\widehat{Cov}(\hat{\beta}_0,\hat{\sigma})\\ 
\widehat{Cov}(\hat{\beta}_1,\hat{\beta}_0)&
\widehat{Var}(\hat{\beta}_1)&
\widehat{Cov}(\hat{\beta}_1,\hat{\sigma})\\
\widehat{Cov}(\hat{\sigma},\hat{\beta}_0)&
\widehat{Cov}(\hat{\sigma},\hat{\beta}_1)&
\widehat{Var}(\hat{\sigma})
\end{array}\right]\\\\\\
&=\left[\begin{array}{ccc}
-\frac{\partial^2\mathcal{L}(\beta_0,\beta_1,\sigma)}{\partial\beta_0^2}& 
-\frac{\partial^2\mathcal{L}(\beta_0,\beta_1,\sigma)}{\partial\beta_0\partial\beta_1}&
-\frac{\partial^2\mathcal{L}(\beta_0,\beta_1,\sigma)}{\partial\beta_0\partial\sigma}\\ 
-\frac{\partial^2\mathcal{L}(\beta_0,\beta_1,\sigma)}{\partial\beta_1\partial\beta_0}& 
-\frac{\partial^2\mathcal{L}(\beta_0,\beta_1,\sigma)}{\partial\beta_1^2}&
-\frac{\partial^2\mathcal{L}(\beta_0,\beta_1,\sigma)}{\partial\beta_1\partial\sigma}\\
-\frac{\partial^2\mathcal{L}(\beta_0,\beta_1,\sigma)}{\partial\sigma\partial\beta_0}& 
-\frac{\partial^2\mathcal{L}(\beta_0,\beta_1,\sigma)}{\partial\sigma\partial\beta_1}&
-\frac{\partial^2\mathcal{L}(\beta_0,\beta_1,\sigma)}{\partial\sigma^2}
\end{array}\right]^{-1}
\end{aligned}
$$

<div class='example'>
### Example 17.4 - $\hat{\Sigma}_{\hat{\theta}}$ for the Computer Execution Time Data
</div>

# 17.4.2 - Standard Errors and Confidence Intervals for $t_p(\mathbf{x})$

# 17.5 - REGRESSION MODEL WITH QUADRATIC $\mu$ AND NONCONSTANT $\sigma$

# 17.5.1 - Quadratic regression relationship for $\mu$ and constant $\sigma$


# 17.5.2 - Quadratic regression model with nonconstant $(\sigma)$


# 17.5.3 - Further comments on the use of empirical regression models


# 17.5.2 - Comment on numerical methods


# 17.6 - CHECKING MODEL ASSUMPTIONS

# 17.6.1 - Definition of residuals


# 17.6.2 - Regression diagnostics


# 17.7 - MODELS WITH TWO OR MORE EXPLANATORY VARIABLES

# 17.7.1 - Model-free graphical analysis of two-variable regression data


# 17.7.2 - Two-variable regression model without interaction


# 17.7.3 - Two-variale regression model with interaction


# 17.8 - PRODUCT COMPARISON: AN INDICATOR VARIABLE REGRESSION MODEL

# 17.8.1 - Comparison of groups using separate analyses


# 17.8.2 - Comparison of groups using combined analyses


# 17.9 - THE PROPORTIONAL HAZARDS FAILURE TIME MODEL

# 17.9.1 - Proportional hazards relationships


# 17.9.2 - The Weibull proportional hazards model


# 17.9.3 - Other proportional hazards models


# 17.9.4 - The semiparametric (Cox) proportional hazards model


# 17.9.5 - PH model applications in reliability


# 17.10 - GENERAL TIME TRANSFORMATION FUNCTIONS

```{r}

```