%chapter 2
%original by wqmeeker  12 Jan 94
%edited by wqmeeker  18 Feb 94
%edited by wqmeeker  27/28 Feb 94
%edited by driker 4 March 94
%edited by driker 18 March 94
%edited by driker 25 March 94
%edited by wqmeeker  26 mar 94
%edited by wqmeeker  28 may 94
%edited by driker 13 july 94
%edited by wqmeeker 16 july 94
%edited by wqmeeker  2 aug 94
%edited by wqmeeker  9 aug 94
%edited by wqmeeker  21 oct 94
%edited by wqmeeker  29 oct 94 Data versus data
%edited by wqmeeker  19/20 nov 94 
%edited by driker 15 dec 94
%edited by driker 2 feb 95
%edited by driker 7 feb 95
%edited by wqmeeker  23/27 june 95
%edited by luis  23 sept 95  clean up model for discrete time
%edited by wqmeeker  23 sept 95 add afr stuff and other changes
%edited by wqmeeker  27 sept 95 luis' suggestions and fit stuff
%edited by wqmeeker   6 oct 95 fixing up the fit stuff
%edited by driker    15 may wayne nelson's comments
%edited by wqmeeker   28 june 96 adding early examples
%edited by driker 1 july 96
%edited by driker 20 nov 96
%edited by wqmeeker   8 mar 97 india changes
\setcounter{chapter}{1}
\chapter{Models, Censoring, and Likelihood for Failure-Time Data}
\label{chapter:np.models.censoring.likelihood}

\input{\chapterhome/common_heading.tex}


%----------------------------------------------------------------------
%----------------------------------------------------------------------

\section*{Objectives}
This chapter explains:
\begin{itemize} 
\item 
Models for continuous failure-time processes.
\item 
Models for the discrete data from
these continuous failure-time processes.
\item 
Common censoring mechanisms that restrict our ability to
observe all of the failure times that might occur in a reliability study.
\item 
Principles of likelihood and how likelihood  is related to the
probability of the observed data.
\item 
How likelihood ideas can be used
to make inferences from reliability data.
\end{itemize}

%----------------------------------------------------------------------
%----------------------------------------------------------------------
\section*{Overview}
This chapter introduces basic concepts of modeling failure-time
processes.  Section~\ref{section:cont.time.proc} explains the basic
relationships among cumulative distributions, densities, survival,
hazard, and quantile functions for modeling of continuous
failure-time processes.  These relationships are used extensively
in subsequent chapters and they are essential background to read the
rest of the book.  Section~\ref{section:model.for.discrete.data}
describes the modeling of discrete data that arise from our limited
ability to observe continuous processes. This section also explains
briefly the importance of censoring, censoring mechanisms, and
important assumptions about censoring mechanisms, needed for proper
application of the methodology in the book.
Section~\ref{section:general.likelihood} introduces likelihood-based
statistical methods. This section provides
general rules for writing the likelihood for reliability data with
several kinds of censoring.  This section is an integral part of the
methodology used in the book and it should be read by most readers.

%----------------------------------------------------------------------
%----------------------------------------------------------------------

%----------------------------------------------------------------------
%----------------------------------------------------------------------
\section{Models for Continuous Failure-Time Processes}
\label{section:cont.time.proc}

As explained in Chapter~\ref{chapter:reliability.data}, the most
widely used metric for reliability of a product is its failure-time
distribution and the most commonly collected reliability data
contain information on the failure times of samples of materials,
components, or of complete systems. This chapter presents basic
models for such data.

Most failure-time processes are modeled on a continuous scale.  This
section describes some common models for describing such processes.
The symbol $\rv$ will be used to denote a nonnegative, continuous
random variable describing the failure time of a unit or system.
%----------------------------------------------------------------------
\subsection{Failure-time distribution functions}
\label{section:ttf.functions}
The probability distribution for failure time $\rv$ can be
characterized by a cumulative distribution function, a probability
density function, a survival function, or a hazard function. These
functions are described below and illustrated, for a typical
failure-time distribution, in
Figure~\ref{figure:pdfcdfhazsf.ps}. The choice of which function or
functions to use depends on convenience of model specification,
interpretation, or technical development. All of these functions are
important for one purpose or another.\\[1ex]
%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/pdfcdfhazsf.ps}
\caption{Failure-time cdf, pdf, sf, and hf corresponding
to Examples~\ref{example:example.cdf} to \ref{example:comp.of.ffsh}.}
\label{figure:pdfcdfhazsf.ps}
\end{figure}
%-------------------------------------------------------------------

\noindent
{\bf Cumulative distribution function.}  The cumulative distribution
function (cdf) of $\rv$, $F(\realrv)=\Pr(\rv \le \realrv)$, gives the
probability that a unit will fail before time $\realrv$.
Alternatively, $F(\realrv)$ can be interpreted as the proportion of
units in the population (or taken from some stationary process) that
will fail before time $\realrv$.  (Here a stationary process is
defined as one that generates units that have a $F(\realrv)$ that
does not change over time.)

\begin{example}
\label{example:example.cdf}{\bf cdf.}
The NW corner of Figure~\ref{figure:pdfcdfhazsf.ps} shows the
particular cdf $F(\realrv)=1-\exp(-t^{1.7})$ for $t$ between 0 and
2.5.
\end{example}

\noindent
{\bf Probability density function.}  The probability density
function (pdf) for a continuous random variable $\rv$ is defined as
the derivative of $F(\realrv)$ with respect to $\realrv$:
$f(\realrv)=dF(\realrv)/d\realrv$. The pdf can be used to represent
relative frequency of failure times as a function of time.  Although
the pdf is less important than the other functions for applications
in reliability, it is used extensively in the development of
technical results.  As illustrated in
Figure~\ref{figure:quantile.def.ps}, the cdf at $t$ is computed as
the area under the pdf from $0$ to $\realrv$, giving the probability
of failing before $\realrv$. That is, $F(\realrv)=\int^\realrv_{0}
f(x)\, dx.$

\begin{example}
\label{example:example.pdf}{\bf pdf.}
Corresponding to Example~\ref{example:example.cdf}, the NE corner of
Figure~\ref{figure:pdfcdfhazsf.ps} shows the particular pdf
$f(\realrv)=dF(\realrv)/d\realrv=1.7t^{.7}\exp(-t^{1.7})$ for $t$
between 0 and 2.5.
\end{example}



\noindent
{\bf Survival function.}
The survival function (sf), also known as the reliability function, is
the complement of the cdf, $S(\realrv)=\Pr(T >
\realrv)=1-F(\realrv)=\int^{\infty}_{\realrv} f(x)\, dx$, and gives the
probability of surviving beyond time $t$.

\begin{example}
\label{example:example.sf}{\bf sf.}
Corresponding to Example~\ref{example:example.cdf}, the SW corner of
Figure~\ref{figure:pdfcdfhazsf.ps} shows the particular sf
$S(\realrv)=1-F(\realrv)=\exp(-t^{1.7})$ for t between 0 and 2.5.
\end{example}

%--------------------
\noindent
{\bf Hazard function.}
%\label{section:nonparametric.hazard.def}
The hazard function (hf), also known as the hazard rate,
the instantaneous failure rate
function and by other names, is defined by
\begin{displaymath}
h(\realrv)=\lim_{\Delta \realrv \rightarrow 0} \frac{\Pr(
\realrv < \rv\le 
\realrv+\Delta \realrv  \mid\rv > \realrv)}{\Delta \realrv} 
= \frac{f(\realrv)}{1-F(\realrv)}.
\end{displaymath}
The hazard function expresses the propensity to fail in the next small
interval of 	 time, given survival to time $\realrv$. That is, for
small $\Delta t$,
\begin{equation}
\label{equation:hazard.prob.approx}
h(\realrv) \times \Delta t \approx \Pr(\realrv < \rv \le \realrv+\Delta t \mid
\rv > \realrv). 
\end{equation}
 
\begin{example}
\label{example:example.hf}{\bf hf.}
Corresponding to Example~\ref{example:example.cdf}, the SE corner of
Figure~\ref{figure:pdfcdfhazsf.ps} shows the particular hf
$h(\realrv)=f(\realrv)/[1-F(\realrv)]=1.7 \times t^{.7}$ for $t$
between 0 and 2.5.
\end{example}

The hazard function can be interpreted as a failure rate in the
following sense. If there is a large number of items [say $n(t)$] in
operation at time $t$, then $n(t) \times h(\realrv)$ is approximately equal to
the number of failures per unit time [or $h(\realrv)$ is
approximately equal to the number of failures per unit time per unit
at risk]. The hazard function has units of fraction failed per unit time.
Because of its close relationship with failure processes
and maintenance strategies, some reliability engineers think of
modeling failure time in terms of $h(\realrv)$.
The ``bathtub curve'' shown in Figure~\ref{figure:bathtubfig.ps} 
provides a useful
conceptual model for the hazard of some product populations. 
%-------------------------------------------------------------------
\begin{figure}
\xfigbookfiguresize{\figurehome/bathtubfig.ps}{4in}
\caption{Bathtub curve hazard function.}
\label{figure:bathtubfig.ps}
\end{figure}
%-------------------------------------------------------------------
There may
be early failures of units with
quality related defects (infant mortality). 
During much of the useful life of a product, 
the hazard may be approximately constant because failures are caused by
external shocks that occur at random. Late-life failures are due to 
wearout. Many reliability studies focus on one side or the other
of this curve.

\mbox{  }\\
\noindent
{\bf Cumulative hazard function.}
For some purposes it is useful to define the function
\begin{displaymath} 
H(\realrv) = \int^{\realrv}_{0} h(x)\,dx
\end{displaymath} 
commonly known as the cumulative hazard function.
The cdf or survival function for $\rv$
can be obtained from the hazard function. For example, for 
any continuous distribution
\begin{equation} 
\label{equation:cum.haz.to.cdf}
F(\realrv)= 1-\exp \left [- H(\realrv)\right]  =1-\exp \left [-\int^{\realrv}_{0} h(x)\,dx \right] .
\end{equation} 

\mbox{  }\\
\noindent
{\bf Average hazard rate.}
The average hazard rate between times $t_{1}$ and $t_{2}$ is
\begin{displaymath}
\ahr(\realrv_{1},\realrv_{2})=\frac{
	\int_{\realrv_{1}}^{\realrv_{2}} h(u) du
         }
	{
	\realrv_{2}-\realrv_{1} 
	} =\frac{
	H(\realrv_{2})-H(\realrv_{1})
         }
	{
	\realrv_{2}-\realrv_{1} 
	}
\end{displaymath}
and can be viewed as a typical hazard rate value over the interval.
Also, if $F(t_{2})-F(t_{1})$ is small (say less than .1), then
\begin{equation}
\label{equation:ahr.interval}
\ahr(\realrv_{1},\realrv_{2}) \approx \frac{
F({\realrv_{2}}) - F({\realrv_{1}})
         }
	{
	\realrv_{2}-\realrv_{1}
	}.
\end{equation}
An important special case arises when $t_{1}=0$ giving
\begin{equation}
\label{equation:ahr.point}
\ahr(\realrv)=\frac{
	\int_{0}^{\realrv} h(u) du
         }
	{
	\realrv
	} =\frac{
	H(\realrv)
         }
	{
	\realrv
	} \approx \frac{
F(t)
         }
	{
	\realrv
	}
\end{equation}
and the approximation is good for small $F(t)$, say $F(t)<.10$. 
The right-hand sides
of (\ref{equation:ahr.interval}) and (\ref{equation:ahr.point})
provide simple interpretation for the $\ahr$ expressions. In either
case, AHR can be interpreted as the approximate fraction failing per
unit time over the specified interval. Of course, if one is really
interested in computing the fraction failing, this is easy to do
directly without any approximation.

\mbox{  }\\
\noindent
{\bf Hazard rate in FITs.}
Especially in high reliability electronics applications, it is common
to express hazard rates in units of FITs. A FIT rate
is defined as the hazard function in units of 1/hours, multiplied
by $10^{9}$.  FITs (from Failures
In Time) were originally
used to describe hazard rates corresponding to components for which
$h(t)$ is {\em constant} over time (a model that will be described in
Section~\ref{section:exponential.distribution}). In such applications,
and when the number of components at risk is large relative to the
number that will fail, FITs can be interpreted, for example, as a
prediction for the number of failures per billion hours of operation
or the number of failures per 1000 hours of operation per one million
units at risk.

The use of FIT rates has carried over to the more modern and realistic
failure models with nonconstant $h(t)$. In this case it is important
to distinguish between a FIT rate for a particular point in time
[$h(t) \times 10^{9}$] or an average from beginning of life to a
particular point in time [$\ahr(t) \times 10^{9}$]; both uses are
common. Because these FIT rates can be vastly different, the
distinction is important.

\begin{example}
{\bf Constant-hazard FIT rate.}
In a large computing network there are 165,000 copies of a particular
component that are at risk to fail. The manufacturer of the components
claims that the component hazard is constant over time at 15 FITs.
Thus $h(t)=15 \times 10^{-9}$ failures per unit per hour
for all time $t$ measured in units
of hours.  A prediction for the
number of failures from this component in one year (8,760 hours) of
operation is $15 \times 10^{-9} \times \mbox{165,000} \times
\mbox{8,760} \approx 217$.
\end{example}

\begin{example}
{\bf Nonconstant-hazard FIT rate.}
The manufacturer of a particular integrated circuit device claims that
the device's hazard function is $h(t)= 1.8\times 10^{-7} \times t^{-.8}$
and time $t$ is measured in units
of hours.
From this, the FIT rate for this population of components at 1 hour is $1.8 
\times 10^{-7} \times (1)^{-.8}
\times 10^{9} = 180 $ FITS.
The FIT rate for this population of
components at 10,000 hours is $1.8 \times 10^{-7}
\times (10000)^{-.8}
\times 10^{9} = .1136 $ FITS.
%splus 1.8*10^(-7)*(10000)^(-.8)* 10^(9) =0.1135723
By simple integration, the average hazard rate to 10,000 hours is
$\ahr(10000)= (1.8/.2) \times 10^{-7}
\times (10000)^{-.8} = 5.68 \times 10^{-10}$ or .568 FITs.
%splus (1.8/.2)*10^(-7)* (10000)^(-.8) = 5.678616e-10
\end{example}

%-------------------------------------------------------------------
\subsection{The quantile function and distribution quantiles}
\label{section:np.quantile.def}
The quantile $\rvquan_{p}$ is the inverse of the cdf; it
is the time at which a specified proportion $p$ of the
population fails. For example $\rvquan_{.20}$ is the time
by which $20 \%$ of the population will fail.  This is illustrated in
Figure~\ref{figure:quantile.def.ps}.
%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/quantile.def.ps}
\caption{Plots showing that the quantile function is the
inverse of the cdf.}
\label{figure:quantile.def.ps}
\end{figure}
%-------------------------------------------------------------------
By definition, the cdf $F(\realrv)$ is nondecreasing. This leaves two
possibilities.
\begin{itemize}
\item
When $F(\realrv)$ is strictly increasing there is a unique value
$\rvquan_{p}$ that satisfies $F(\rvquan_{p})=p$, and we write
$\rvquan_{p}=F^{-1}(p)$.
\item 
When $F(\realrv)$ is constant (i.e., flat)
over some interval or intervals, there can
be more than one solution $t$ to the equation $F(t)=p$.  Taking
$\rvquan_{p}$ equal to the smallest value of $\realrv$ satisfying
$F(t)=p$ is the standard convention.
\end{itemize}
In general, for $0 < p < 1 $, we define the $p$ quantile of
$F(\realrv)$ as the {\em smallest} time $\rvquan$ such that
$\Pr(\rv \le \rvquan)=F(\rvquan)\geq p$.

\begin{example}
\label{example:example.quantile}{\bf Quantile function.}
Using $p=F(\realrv)=1-\exp(-t^{1.7})$ from
Example~\ref{example:example.cdf}, solving 
for $t$ gives $t_{p} = [-\log(1-p)]^{1/1.7}$
and $t_{.2} = [-\log(1-.2)]^{1/1.7} = .414$,
as shown in Figure~\ref{figure:quantile.def.ps}.
\end{example}

%-------------------------------------------------------------------
%-------------------------------------------------------------------
\section{Models for Discrete Data from a Continuous Process}
\label{section:model.for.discrete.data}
Most failure-time processes are modeled on a continuous scale.
Because of inherent limitations in measurement precision, however,
failure-time
data are {\em always} discrete. Limitations in ability to
observe or in a measuring instrument's ability to record can cause
data to be censored or truncated, as illustrated in the examples
in Section \ref{section:data.examples}.  The rest of this chapter
develops a general structure for modeling such data. Subsequent sections
describe different kinds of observations that arise in reliability
data analysis and show how to compute the likelihood (or ``probability
of the data'').

%-------------------------------------------------------------------
\subsection{Multinomial failure time model}
\label{section:multinomial.failure.model}
Because all data are discrete, it is convenient to partition the time
line $(0, \infty)$ into $m+1$ observation intervals.  The
partitioning depends on inspection times, measurement precision, and/or
roundoff; it can be expressed as follows:
\begin{equation}
\label{equation:small.intervals}
(\realrv_{0}, \realrv_{1}],\,
(\realrv_{1}, \realrv_{2}],\, \ldots,\,
(\realrv_{m-1}, \realrv_{m}],\,
(\realrv_{m}, \realrv_{m+1})
\end{equation}
where $\realrv_{0}=0$ and $\realrv_{m+1}=\infty.$ This partition
is illustrated in
Figure~\ref{figure:multinomialfig.ps}.  For example, if failure times
are recorded to the nearest hour, then each interval would be 1-hour
long, up until $\realrv_{m}$, the last
recording. In general, these intervals need not be of equal length.
Observe that the last interval is of infinite length. Define
\begin{equation}
\label{equation:def.of.pi}
\pi_{i}=\Pr(\realrv_{i-1} < \rv 
\le \realrv_{i})=F(\realrv_{i})-F(\realrv_{i-1})
\end{equation}
as the multinomial probability that a unit will fail in interval $i$.
Note that $\pi_{i} \geq 0$ and $\sum_{j=1}^{m+1} \pi_{j}=1$.
The survival function evaluated at 
$\realrv_{i}$ is $S(\realrv_{i})=
\Pr(\rv > \realrv_{i})=1-F(\realrv_{i})=\sum_{j=i+1}^{m+1} \pi_{j}$.
%-------------------------------------------------------------------
\begin{figure}
%\begin{center}
\xfigbookfiguresize{\figurehome/multinomialfig.ps}{4.0in}
%\end{center} 
\caption{Partitioning of time into nonoverlapping intervals.}
\label{figure:multinomialfig.ps}
\end{figure}
%-------------------------------------------------------------------
Then
\begin{equation}
\label{equation:pvec.def}
p_{i}=\Pr(\realrv_{i-1}<\rv \le \realrv_{i}
\mid  \rv > \realrv_{i-1})
=\frac{F(\realrv_{i})-F(\realrv_{i-1})}
     {1-F(\realrv_{i-1})}
=\frac{\pi_{i}}{S(\realrv_{i-1})}
\end{equation}
is the conditional probability that a unit will 
fail in interval $i$, given that the unit was
still operating at the beginning of interval $i$.
Thus
$p_{m+1}=1$ but the only restriction on 
$p_{1},\ldots,p_{m}$ is $0\leq p_{i} \leq 1$.

\subsection{Multinomial cdf}
Using (\ref{equation:pvec.def}), it is easy to show that
\begin{equation}
\label{equation:discrete.survival.function}
S(\realrv_{i})=\prod_{j=1}^{i}\left [ 1 - p_{j} \right ],
\,\,\,i=1,\ldots,m+1.
\end{equation}
This result and those following are important for data analysis methods
developed in Chapter~\ref{chapter:nonparametric.estimation}.
Then the cdf of $\rv$, evaluated at 
$\realrv_{i}$ can be expressed as
\begin{displaymath}
F(\realrv_{i})= 1 - \prod_{j=1}^{i}\left [ 1 - p_{j} \right ],
\,\,\,i=1,\ldots,m+1
\end{displaymath}
or as
\begin{equation}
\label{equation:f.is.sum.of.pi}
F(\realrv_{i})= \sum_{j=1}^{i} \pi_{j},
\,\,\,i=1,\ldots,m+1.
\end{equation}
Thus $\pivec=(\pi_{1}, \ldots, \pi_{m+1})$ or 
$\pvec=(p_{1}, \cdots, p_{m})$ are alternative sets of {\em basic
parameters} to model discrete failure-time data.

%-------------------------------------------------------------------
\begin{figure}
\xfigbookfiguresize{\figurehome/start.pi.deffig.ps}{3.0in}
\caption{Graphical interpretation of the relationship between the
 $\pi_{i}$ values and $F(t)$. }
\label{figure:start.pi.deffig.ps}
\end{figure}
%-------------------------------------------------------------------
%-------------------------------------------------------------------
\begin{table}
\caption{Table illustrating probabilities for the
multinomial failure time model computed
from $F(\realrv)=1-\exp(-t^{1.7})$.}
\centering\small
\begin{tabular} {rrrrrrr}
\\[-.5ex]
\hline
\\[-1.5ex]
   i  & $t_{i}$ & $F(\realrv_{i})$ & $S(\realrv_{i})$ & $\pi_{i}$ &
$p_{i}$&  $1- p_{i}$ \\ \hline
 0 & 0 & .000 & 1.000 &  &  &  \\
 1 & .5 & .265 & .735 & .265 & .265 & .735 \\
 2 & 1 & .632 & .368 & .367 & .500 & .500 \\
 3 & 1.5 & .864 & .136 & .231 & .629 & .371 \\
 4 & 2 & .961 & .0388 & .0976 & .715 & .285 \\
 5 &  $\infty$ & 1.000 & .000 & .0388 & 1.000 & .000 \\ \hline
 &&&& 1.000
\end{tabular}  
\label{table:multi.examp}
\end{table}
%--------------------------------------------
\begin{example}
{\bf Computation of $\boldsymbol{F(\realrv_{i})}$,
$\boldsymbol{S(\realrv_{i})}$, $\boldsymbol{\pi_{i}}$, and
$\boldsymbol{p_{i}}$}.
\label{example:comp.of.ffsh} 
Table~\ref{table:multi.examp} shows values of
$F(\realrv_{i})$, $S(\realrv_{i})$, $\pi_{i}$, and $p_{i}$ based on
cdf $F(\realrv)=1-\exp(-t^{1.7})$ used in
Examples~\ref{example:example.cdf} through
\ref{example:example.quantile}. The quantities
in the table illustrate the use of (\ref{equation:def.of.pi}),
(\ref{equation:pvec.def}),
(\ref{equation:discrete.survival.function}), and
(\ref{equation:f.is.sum.of.pi}) for inspections at .5, 1, 1.5, 2, and
2.5 (note that some arithmetic using values in the table may be off a
little in the last digit due to the limited precision in the 3 digits
shown in the table).  Figure~\ref{figure:start.pi.deffig.ps} shows,
graphically, the relationship between the $\pi$ values and $F(t)$ for
this example.
\end{example}


%-------------------------------------------------------------------
%-------------------------------------------------------------------
\section{Censoring}
%-------------------------------------------------------------------
\subsection{Censoring mechanisms}
\label{section:censoring.mechanisms}
Censoring restricts the ability to observe failure times exactly.  As
illustrated in the examples in Chapter~\ref{chapter:reliability.data},
censoring is common in reliability data analysis and arises for a
number of different reasons.
\begin{itemize}
\item 
Generally there are constraints on the length of life tests or other
reliability studies and, as a result, data have to be analyzed before
all units have failed.  Removing unfailed units from test at a
prespecified time is known as ``time-censoring'' or ``Type~I
censoring.'' Units may be tested simultaneously or in sequence (e.g.,
because of a limited number of test positions).
Examples~\ref{example:lfp.data} and
\ref{example:electronic.subsystem.data} illustrate time-censoring.
\item 
A life test that is terminated after a specified number of failures
results in ``failure censoring,'' also known as ``Type~II
censoring.''  Although the statistical properties of estimates from
failure-censored data are simpler than the corresponding properties
from time-censored data, failure-censored tests are less common in
practice.
\item 
In many life tests, failures are discovered only at times of
inspection. Interval-censored observations consist of upper and
lower bounds on a failure time. Such data are also known as
inspection data, grouped data, or read-out data.  If a unit has
failed at its first inspection, it is the same as a left-censored
observation. If a unit has not failed by the time of the last
inspection, it is right censored, the upper endpoint of the
interval being $\infty$. See
Examples~\ref{example:heat.exchanger.data} and
\ref{example:heat.transmitter.tube.data}.
If each unit has only one inspection time (perhaps differing from
unit to unit), and where the observation is on whether the unit
failed or not, the data are known as quantal-response data, as in
Example~\ref{example:turbine.wheel.data}.
\item
Some products have more than one cause of failure.  If primary
interest is focused on one particular cause of failure, failure from
other causes (sometimes known as competing risks) can, in some
situations, be viewed as a form of {\em random right censoring}.
This kind of random censoring can lead to multiple right censoring
where some failure times and censoring times are intermixed as in
Example~\ref{example:shock.absorber.data}.
\item
In some situations units are introduced into the field or put on test
at different times. This is known as staggered entry. If the data
are to be analyzed at a point in time when not all units have failed,
the data will, usually, be multiply right censored with some
failure times again exceeding some of the running times as in
Example~\ref{example:fan.data}. Censoring due to staggered entry of
units is a type of {\em systematic multiple censoring}.

If it is a reasonable approximation that units manufactured over the period of
time came from the same process, the data could be pooled together and
analyzed to make inferences about that process.  Often, however, a
process or product design will change over time and pooling such data
could lead to misleading conclusions.  Caution is advised and it is
good practice to look for time trends in data.
The case study in Section~\ref{section:cen.mixed.pop} illustrates such
a situation.
\end{itemize} 

%-------------------------------------------------------------------
\subsection{Important assumptions on censoring mechanisms}
\label{section:import.cen.assump}
Use of most models and methods to analyze censored data
implies important assumptions about the nature of the censoring
and its relationship to the failure process.
Simply stated, a censoring time (i.e., the time at which we stop
observing a unit that has not failed) can be either random or
predetermined.  In order for standard censored data analysis methods
to be valid, it is necessary that the censoring time of a unit depend
only on the history of the observed failure-time process. Using future
events (or indicators of future events) to stop observing a unit could
introduce bias. This cause-of-censoring assumption would be violated, 
for example, if
units were taken off test before actual failure, but in response to
some precursor to a future failure (e.g., increase in vibration for an
electrical motor).  For the standard censoring mechanisms described in
Section~\ref{section:censoring.mechanisms}, the stopping times
depend only on the history of the observed failure-time process.
Relatedly, standard methods of analyzing censored data require
the assumption that censoring
is noninformative. This implies that the censoring times
of units provide no information about the failure-time distribution.

%-------------------------------------------------------------------
%-------------------------------------------------------------------
 \section{Likelihood}
\label{section:general.likelihood}
%-------------------------------------------------------------------
\subsection{Likelihood-based statistical methods}

The general idea of likelihood inference is to
fit models to data by entertaining
model-parameter combinations for which the probability of the data is
large.  Model-parameter combinations with relatively high
probabilities are more plausible than combinations with low
probability.  Likelihood methods provide general and versatile tools
for fitting models to data.  The methods can be applied with a wide
variety of parametric and nonparametric models with censored,
interval, and truncated data.  It is also possible to fit models with
explanatory variables (i.e., regression analysis).

There is well-developed large-sample likelihood theory for
regular models that provides straightforward methods for fitting models
to data. The theory guarantees that these methods are, in large
samples, statistically efficient (i.e., yield the most
accurate estimates). These properties are approximate in moderate and
small sample sizes, and various studies have shown that likelihood
methods generally perform as well as other available methods. With
censored data, ``large-sample'' really means ``large number of
failures'' and a typical guideline for large is 20 or more, but
this really depends on the problem and the questions to be answered.

Likelihood theory can be extended to more complicated {\em nonregular}
models and the basic concepts are similar.  Also, much current
statistical research is focused on the development of more refined,
but computationally intensive methods that will work better for
smaller sample sizes.



%-------------------------------------------------------------------
\subsection{Specifying the likelihood function}
\label{section:probability.of.data}
The likelihood function is either equal to or approximately proportional
to the probability of the data.
This section describes a general method of computing the
probability of a given data set. Then, 
for a given set of data and specified model, the likelihood is viewed as
a function of the unknown model parameters (where we can use either the
$\pi_{i}$'s or the $p_{i}$'s in the multinomial model introduced in
Section~\ref{section:model.for.discrete.data}).
The form of the likelihood
function will depend on factors like
\begin{itemize}
\item
The assumed probability model.
\item
The form of available data (censored, interval censored, etc.).
\item
The question or focus of the study. This includes
issues relating to identifiability of parameters (i.e., the data's ability
or inability to estimate certain features of a statistical model).
\end{itemize}

The total likelihood can be written as
the joint probability of the data.  Assuming $n$ independent
observations, the sample likelihood is
\begin{equation}
\label{equation:probability.of.data}
\like(\pvec)= \like(\pvec;\DATA)= \likeconstant \prod_{i=1}^{n}
\like_{i}(\pvec;\data_{i})
\end{equation}
where $L_{i}(\pvec;\data_{i})$ is the probability of the observation $i$,
$\data_{i}$ is the data for observation $i$, and $\pvec$ is the vector
of parameters to be estimated.
To estimate $\pvec$ from the available $\DATA$, we find the values of
$\pvec$ that maximize $\like(\pvec)$.  In the usual situations
where the constant term $\likeconstant$ in
(\ref{equation:probability.of.data}) does not depend on $\pvec$, one can
simply take $\likeconstant=1$ for purposes of estimating
$\pvec$ (see Section \ref{section:form.of.constant} for more
information on $\likeconstant$).
The likelihood in (\ref{equation:probability.of.data}) can also be
written as a function of the multinomial cell probabilities $\pivec$.
Similarly, if there is a specified parametric form for
$F(t;\thetavec)$ the likelihood can be written as a
function of the parameters $\thetavec$.  We use $\pvec$ here because
Chapter~\ref{chapter:nonparametric.estimation} illustrates the direct
estimation of $\pvec$.

%----------------------------------------------------------------------
\subsection{Contributions to the likelihood function}
%-------------------------------------------------------------------
\label{section:likelihood.contributions}


Figure~\ref{figure:interval.probability.ps} illustrates the intervals
of uncertainty for examples of left-censored, interval-censored, and
right-censored observations.  The likelihood contributions for each of
these cases, shown in Table~\ref{table:censoring.types}, is simply the
probability of failing in the corresponding interval of uncertainty.


\mbox{  }\\
\noindent
%---------------------------------------------
\noindent
{\bf Interval-censored observations.}
If a unit's failure time is known to have occurred
between times $\realrv_{i-1}$ and $\realrv_{i}$, the probability
of this event is
\begin{equation}
\label{equation:interval.censored.likelihood}
\like_{i}(\pvec)=
\int_{\realrv_{i-1}}^{\realrv_{i}}f(t)\,dt=
F(\realrv_{i})-F(\realrv_{i-1}).
%\label{equation:interval.likelihood}
\end{equation}
The three middle rows in Table~\ref{table:v7.transmitter.tube} are
examples of interval-censored observations. 
%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/interval.probability.ps}
\caption{Likelihood contributions for different kinds of censoring.}
\label{figure:interval.probability.ps}
\end{figure}

\begin{example}{\bf Likelihood for an interval censored observation.}
Refer to Figure~\ref{figure:interval.probability.ps} and
Table~\ref{table:multi.examp}. If a unit is still operating at the
$t=1.0$ inspection but a failure is found at the $t=1.5$ inspection,
then the likelihood (probability) for the interval censored
observation is $\pi_{i}=F(1.5) - F(1.0) = .231 $.
\end{example}

Although most data arising
from observation of a continuous-time process can be thought of as
having occurred in intervals similar to $(\realrv_{i-1},
\realrv_{i}]$, the following important special cases warrant separate
consideration.

\noindent
{\bf Left-censored observations.}
Left-censored observations occur in life-test applications when a unit
has failed at the time of its first inspection; all that is known is
that the unit failed before the inspection time (e.g., the first row
of Table~\ref{table:v7.transmitter.tube}). In other situations,
left-censored observations arise when the exact value of a response
has not been observed and we have instead, an upper bound on that
response. Consider, for example, a measuring instrument that lacks the
sensitivity needed to measure observations below a known threshold
(e.g., a noise floor in an ultrasonic measuring system).  When the
measurement is taken, if the signal is below the instrument threshold,
all that is known is that the measurement is less than the threshold.
If there is an upper bound $\realrv_{i}$ for observation $i$, causing
it to be left censored, the probability and likelihood contribution of
the observation is
\begin{equation}
\label{equation:left.censored.likelihood}
\like_{i}(\pvec)=\int_{0}^{\realrv_{i}}f(t)\,dt=
F(\realrv_{i})-F(0)=
F(\realrv_{i}).
\end{equation}
Equation (\ref{equation:pvec.def}) shows how $\like_{i}$ can be
written as a function of $\pvec$. Alternatively,
(\ref{equation:def.of.pi}) shows how $\like_{i}$ can be written as a
function of $\pivec$.  Note that a left-censored observation can also
be considered to be an interval censored observation between 0 and
$t_{i}$.

\begin{example}{\bf Likelihood of a left-censored observation.}
Refer to Figure~\ref{figure:interval.probability.ps} and
Table~\ref{table:multi.examp}. If a failure is found at the first
inspection time $t=.5$, then the likelihood (probability) for the left
censored observation is $F(.5) = .265$.
\end{example}

%---------------------------------------------
\noindent
{\bf Right-censored observations.}
Right censoring is common in reliability data
analysis.  For example, the last bin in
Table~\ref{table:v7.transmitter.tube} contains all lifetimes greater
than 100 days.  The observations in this bin are right-censored
because all that is known about the failure times in this bin is
that they were greater than 100 days.

If there is a lower bound $\realrv_{i}$ for the $i$th failure time,
the failure time is somewhere in the interval $(\realrv_{i},
\infty)$. Then the probability and likelihood contribution for this
right-censored observation is
\begin{equation}
\label{equation:right.censored}
\like_{i}(\pvec)=\int_{\realrv_{i}}^{\infty}f(t)\,dt=
F( \infty )-F(\realrv_{i})=
1-F(\realrv_{i}).
\end{equation}

\begin{example}{\bf Likelihood of a right-censored observation.}
Refer to Figure~\ref{figure:interval.probability.ps} and
Table~\ref{table:multi.examp}. If a unit has not failed by the last
inspection at $t=2$, then the likelihood (probability) for the right
censored observation is $1-F(2) = .0388$.
\end{example}


\begin{table}
\caption{Contributions to likelihood for life table data.}
\centering\small
\begin{tabular}{lll}
\\[-.5ex]
Censoring Type &Range
& Likelihood \\ \hline \\
$d_{i}$ observations\\
interval censored & $\realrv_{i-1} < \rv \le
\realrv_{i}$& 
$\left [F(\realrv_{i})-F(\realrv_{i-1})  \right ]^{d_{i}}$\\
in $\realrv_{i-1}$ and $\realrv_{i}$ \\[2ex]
$\scl_{i}$ observations\\
left censored at $\realrv_{i}$ & $\rv \le
\realrv_{i}$&$ \left [F(\realrv_{i})\right ]^{\scl_{i}}$ 
\\[2ex]
$r_{i}$ observations\\
right censored at $\realrv_{i}$ & $\rv > \realrv_{i}$&
$\left [1-F(\realrv_{i}) \right ]^{r_{i}}$
\\[1ex]
\hline
\end{tabular}
\label{table:censoring.types}
\end{table}

%---------------------------------------------
\noindent
{\bf Total likelihood.}
The total likelihood, or joint probability of
the $\DATA$, for
$n$ independent observations is
\begin{eqnarray}
\label{equation:likelihood.over.intervals}
\like(\pvec;\DATA)&=&\likeconstant
\prod_{i=1}^{n} \like_{i}(\pvec;\data_{i})
\\ \nonumber
&=& \likeconstant
\prod_{i=1}^{m+1}
 \left [F(\realrv_{i}) \right]^{\scl_{i}}
 \left [F(\realrv_{i})-F(\realrv_{i-1}) \right ]^{d_{i}}
 \left [1-F(\realrv_{i}) \right ]^{r_{i}}
\end{eqnarray}
where $n=\sum_{j=1}^{m+1} \left (\deadin_{j}+r_{j}+\scl_{j} \right )$
and $\likeconstant$ is a constant depending on the sampling inspection
scheme but not on the parameters $\pvec$.  So we can take
$\likeconstant=1$.  We want to find $\pvec$ so that $\like(\pvec)$ is
large.  The $\pvec$ that maximizes $\like(\pvec)$ provides a maximum
likelihood estimate of $F(\realrv)$.  For some problems, it will be
more convenient to write the likelihood and do the optimization in
terms of $\pivec$. As described in
Section~\ref{section:multinomial.failure.model}, either set of basic
parameters can be used.

%-------------------------------------------------------------------
\subsection{Form of the constant term $\likeconstant$}
\label{section:form.of.constant}
The form of constant term $\likeconstant$ in 
(\ref{equation:probability.of.data}) and 
(\ref{equation:likelihood.over.intervals})
depends on the underlying
sampling and censoring mechanisms and is difficult to
characterize in general. For our multinomial model,
assuming inspection data and {\em no losses} (i.e., no 
right-censored observations before the last interval),
 \begin{displaymath}
	\likeconstant=\frac{n!}{\deadin_{1}! \cdots \deadin_{m+1}!}
 \end{displaymath}
which is the usual multinomial coefficient.
Another important special case arises
when we increase the number of intervals,
approaching continuous inspection. Then with an underlying continuous
failure-time process (so there will be no ties), all
$\deadin_{i}$'s will be either 0 or 1 depending on whether
there is a failure or not in interval $i$.
In this case $\likeconstant$ reduces to $n!$,
corresponding to the number of permutations of the $n$ order
statistics.
With Type~I single-time censoring at
$\realrv_{m}$ and no more than one failure in any 
of the intervals before $\realrv_{m}$, $\likeconstant=n!/r_{m+1}!$,
where $r_{m+1}=\deadin_{m+1}$ is the number of right-censored
observations, all of which are beyond $\realrv_{m}$.

Because, for most models, $\likeconstant$ is a constant 
that does not depend on the model parameters, it is common
practice to take $\likeconstant=1$ and suppress 
$\likeconstant$ from likelihood expressions and computations.

\subsection{Likelihood terms for general reliability data}
\label{section:general.likelihood.terms}
Although some reliability data sets are reported in life-table form
(e.g., Table~\ref{table:v7.transmitter.tube}),
other data sets report only the times or the intervals in which failures
actually occurred or observations were censored.  For such data sets
there is an alternative, more general form for writing the likelihood.
This form of the likelihood is commonly used as input for computer
software for analyzing failure-time data.  In general, 
observation $i$ consists of an interval $(\realrv_{i}^{L},\realrv_{i}]$,
$i=1, \ldots, n$ that contains the failure
time $\rv$ for unit $i$ in the sample. The intervals
$(\realrv_{i}^{L},\realrv_{i}]$ may overlap and their union may not
cover the entire time line $(0, \infty)$. In general $\realrv_{i}^{L}
\ne \realrv_{i-1}$. Assuming that the censoring is at $\realrv_{i}$
the likelihood for individual observations can be computed as shown in
Table~\ref{table:general.likelihood.terms},
%---------------------------------------------
\begin{table}
\caption{Contributions to the likelihood for general failure time data.}
\centering\small
\begin{tabular}{lll} 
\\[-.5ex]
Type of   &                  &  Likelihood of  a single
\\ 
Observation & Characteristic & Response $\like_{i}(\pvec;\data_{i})$
\\ \hline
\\
Interval censored & $\realrv_{i}^{L} < \rv \le
\realrv_{i}$&
$F(\realrv_{i})-F(\realrv_{i}^{L})$ \\[1ex]
 Left censored at $\realrv_{i}$ & $\rv \le
\realrv_{i}$ &$ F(\realrv_{i})$ 
\\[1ex]
Right censored at $\realrv_{i}$ & $\rv > \realrv_{i}$& 
$1-F(\realrv_{i}) $ \\[1ex]
\hline
\end{tabular}
\label{table:general.likelihood.terms}
\end{table}
%---------------------------------------------
the joint likelihood for the $\DATA$
with $n$ independent observations is
\begin{displaymath}
\like(\pvec;\DATA)=
\prod_{i=1}^{n}  \like_{i}(\pvec;\data_{i}).
\end{displaymath}
Some of the failure times or intervals may appear more than once
in a data set. Then
$w_{j}$ is used to denote the frequency (weight or multiplicity) of
such identical observations and
\begin{equation}
\label{equation:like.group.censoring}
\like(\pvec;\DATA)=
\prod_{j=1}^{k} \left[\like_{j} (\pvec;\data_{j})\right]^{w_{j}}.
\end{equation}


Chapter~\ref{chapter:nonparametric.estimation} shows how to compute
the maximum likelihood estimate of $F(\realrv)$ without having to
make any assumption about the underlying distribution of $\rv$.
Starting in Chapter~\ref{chapter:parametric.ml.one.par} we show how to
estimate a small number of unknown parameters from a more highly
structured parametric model for $F(\realrv)$.

%------------------------------------------------------------------------------
\subsection{Other likelihood terms}
The likelihood contributions used in 
(\ref{equation:likelihood.over.intervals}) 
and (\ref{equation:like.group.censoring}) will cover the
vast majority of reliability data analysis problems that
arise in practice. There are, however, other kinds of
observations and corresponding likelihood contributions
that can arise and these can
be handled with only a slight extension of this framework.

%-------------------------------
\mbox{  }\\
\noindent
{\bf Random censoring in the intervals.}
Until now, it has been assumed that right censoring occurs at the end of
the inspection intervals. If $C$ is a random censoring time, an
observation is censored {\em in} the interval $(\realrv_{i-1},
\realrv_{i}]$ if $\realrv_{i-1} < C \le \realrv_{i}$ and $C
\le \rv$.  Similarly, an observation is a failure in that interval if
$\realrv_{i-1} < \rv \le \realrv_{i}$ and $\rv \le C$. To account for
right-censored observations that occur at unknown random points 
in the intervals, one usually assumes that the censoring is determined 
by a random variable $C$ with
pdf $f_C(\realrv)$ and cdf $F_C(\realrv)$ and that the failure
time $\rv$ and censoring time $C$ are statistically independent
(but it is important to recognize that making such an assumption does
not make it so!).   Then for
continuous $T$, the joint probability (likelihood) for $r_{i}$ right
censored observations in $(\realrv_{i-1}, \realrv_{i}]$ and
$d_{i}$ failures in $(\realrv_{i-1}, \realrv_{i}]$ is
\begin{eqnarray}
\like_{i}(\pvec;\data_{i})&=&
 \left \{
 \Pr
 \left [
 \left (
      \rv \le  C
 \right )
  \cap
 \left (
 \realrv_{i-1} < \rv \le \realrv_{i}
 \right )
 \right ]
	  \right \}^{d_{i}}
 \left \{
 \Pr
 \left [
 \left (
   C \le  \rv
 \right )
  \cap
 \left (
 \realrv_{i-1} < C \le \realrv_{i}
 \right )
 \right ]
\right \}^{r_{i}} \nonumber
\\
\label{equation:like.censoring.in.interval}
&=&
 \left \{
\int_{\realrv_{i-1}}^{\realrv_{i}}
   f_{ \rv }(\realrv) \left [
	   1-F_{C}(\realrv)
	  \right ] d\realrv
\right \}^{d_{i}}
\times 
 \left \{
\int_{\realrv_{i-1}}^{\realrv_{i}}
   f_C(\realrv) \left [
	   1-F_{ \rv }(\realrv)
	  \right ]d\realrv
\right \}^{r_{i}}.
\end{eqnarray}

\begin{example}
\label{example:morgan.battery.data}
{\bf Battery failure data with multiple failure modes.} Morgan~(1980)
presents data from a study conducted on 68 battery cells. The purpose
of the test was to determine early causes of failure, to determine
which causes reduce product life the most, and to estimate
failure-time distributions.  Each test cell was subjected to automatic
cycling (charging and discharging) at normal operating conditions.
Some survived until the end of the test and others were removed before
failure for physical examination. The original data giving precise
times of failure or removal were not available.  Instead, the data in
Appendix Table~\ref{atable:morgan.battery.data} provide a useful
summary. By the nature of this summary, however, the removals
(censoring times) do not occur at the ends of the intervals (as in the
examples in Chapter~\ref{chapter:reliability.data}).
\end{example}

%-------------------------------
\noindent
{\bf Truncated data.} In some reliability studies, observations may be
{\em truncated}.  Truncation, which is similar to but different from
censoring, arises when observations are actually observed only when
they take on values in a particular range. For observations that fall
outside the certain range, the {\em existence} is not known (and
this is what distinguishes truncation from censoring).  Equivalently,
sampling from a truncated distribution leads to truncated data.
Examples and appropriate likelihood-based methods for handling
truncated data, based on conditional probabilities, will be given in
Section~\ref{section:truncated.data}.


%----------------------------------------------------------------------
%----------------------------------------------------------------------

\section*{Bibliographic Notes}
Theory for likelihood inference based on grouped and multinomial data
has been given, for example, by Kulldorff~(1961), Rao~(1973), and
Elandt-Johnson and Johnson~(1980).  Aalen and Husebye~(1991), in a biomedical
context, describe a general structure for 
observation stopping times that can be
viewed as the cause of censoring. They explain the conditions under
which the likelihood methods in this chapter are appropriate and give
examples of stopping rules that could lead to biased inferences.
Lagakos~(1979), Kalbfleisch and Prentice~(1980), and Lawless~(1982,
Chapter~1) also discuss these issues.


%-------------------------------------------------------------------
\section*{Exercises}

%-------------------------------------------------------------------
\begin{exercise}
Although the diesel generator fan failure times in Appendix Table
\ref{atable:fan.data} were reported as exact failures, the ties
suggest that the data are really discrete due to rounding or because
failures were found on inspection. Suggest appropriate partitioning of the
time line to reflect the true discrete nature of the data. Explain how
you arrived at this partitioning.  Use this partitioning to develop an
expression for the discrete-data likelihood.
\end{exercise}

%-------------------------------------------------------------------
\begin{exercise}
It is possible for a continuous cdf to be constant over some
intervals of time.
\begin{enumerate}
\item
Give an example of a physical situation that would result in a cdf
$F(t)$ that is constant over some values of $t$.
\item 
Sketch such a
cdf and its corresponding pdf.  
\item 
For your example, explain why the
convention for defining quantiles given in
Section~\ref{section:np.quantile.def} is sensible.  Are there
alternative definitions that would also be suitable?
\end{enumerate}
\end{exercise}


%-------------------------------------------------------------------
\begin{exercise}
Consider a random variable with
cdf $F(\realrv)=t/2$, $0 < t \leq 2$. Do the following:
\begin{enumerate}
\item
\label{exercise.part:unif.haz}
Derive expressions for the corresponding pdf and hazard functions.
\item
Use the results of part~\ref{exercise.part:unif.haz} to verify
the relationship given in (\ref{equation:cum.haz.to.cdf}).
\item
Sketch (or use the computer to draw) the cdf and pdf functions.
\item
Sketch (or use the computer to draw) the hazard function.
Give a clear intuitive reason for the behavior of $h(t)$ as
$t \rightarrow 2$. Hint: by the time $t=2$, all units in the
population
must have failed.
\item
Derive an expression for $\realrv_{p}$, the $p$ quantile of $F(\realrv)$,
and use this expression to compute $\realrv_{.4}$. Illustrate this on
your plots of the cdf and pdf functions.
\item
Compute $\Pr(.1 < \rv \leq .2)$ and
$\Pr(.8 < \rv \leq .9)$. Illustrate or indicate this 
probabilities on your graphs. 
\item
\label{exercise.part:unif.haz.prob.approx}
Compute $\Pr(.1 < \rv \leq .2 \mid \rv>.1)$ and
$\Pr(.8 < \rv \leq .9 \mid \rv > .8)$. 
Compare your answers with the approximation in
(\ref{equation:hazard.prob.approx}). 
\item
Explain the results in 
in part \ref{exercise.part:unif.haz.prob.approx}
and give a general result on the relationship 
between 
$\Pr(\realrv< \rv< \realrv \mid \rv>\realrv)$ 
and the approximation in
(\ref{equation:hazard.prob.approx}). 
\end{enumerate}
\end{exercise}


%-------------------------------------------------------------------
\begin{exercise}
Consider a  cdf $F(t)=1-\exp[-(t/\eta)^{\beta}]$, $t > 0, \eta >0, 
\beta >0$. (This is the cdf of the
Weibull distribution, which will be discussed in detail in
Chapter~\ref{chapter:ls.parametric.models}.)
\begin{enumerate}
\item
Derive an expression for the pdf $f(t)$.
\item
Derive an expression for the hazard function $h(t)$.
\item
Sketch (or use the computer to draw) the cdf, pdf, and hazard
functions
for $\weibscale=1$ and $\beta=$ .5, 1, and 2.
\end{enumerate}
\end{exercise}

%-------------------------------------------------------------------
\begin{exercise}
Consider a cdf $F(\realrv)=1-\exp(-t)$, $t>0$. Do the following.
\begin{enumerate}
\item
Derive expressions for the corresponding pdf and hazard functions.
\item
Sketch (or use the computer to draw) the cdf, pdf, and hazard functions.
\item
Derive an expression for $\realrv_{p}$, the $p$ quantile of $F(\realrv)$,
and use this expression to compute
$\realrv_{.1}$. Illustrate this on your plots of the cdf and pdf functions.
\item
Compute $\Pr(.1 < \rv \leq .2)$. Illustrate this probability on your
graphs. Compare your answer with the approximation in
(\ref{equation:hazard.prob.approx}).
\end{enumerate}
\end{exercise}


%-------------------------------------------------------------------
\begin{exercise1}
Consider a continuous random variable with cdf $F(t)=1-\exp(-t)$ and the partitioning
time points $\realrv_{0}=0$, $\realrv_{1}=.1$,
$\realrv_{2}=.2$, $\realrv_{3}=.5$, $\realrv_{4}=1$,
$\realrv_{5}=2$, $\realrv_{6}=\infty$ to do the following:
\begin{enumerate}
\item
Sketch (or use the computer to make)
a graph of $F(t)$ over the range $0 < t \leq 10$.
\item
Compute and make a table
of values of $F(t_{i})$, $S(t_{i})$, and $\pi_{i}$, $p_{i}$
at $\realrv_{i}$ for $i=1, \ldots, 6$.
\end{enumerate}
\end{exercise1}

%-------------------------------------------------------------------
\begin{exercise}
An electronic system contains 20 copies of a particular integrated
circuit that is at risk to failure during operation.  The manufacturer
of the component claims that the component's average hazard rate over
the first two years of operation is 75 FITs.  For the 1500 systems
that are currently in operation, compute a prediction for the total number
of these integrated circuits that will fail over the next two years
of operation.
\end{exercise}

%-------------------------------------------------------------------
\begin{exercise}
Write an expression for the likelihood of the turbine wheel data in
Table \ref{table:turbine.data}.  Also give an explicit expression for
the constant term $\likeconstant$.  How would the likelihood differ if
we knew the actual service time of each of the inspected turbine
wheels?
\end{exercise}

%-------------------------------------------------------------------
\begin{exercise}
Consider the V7 vacuum tube data in Table~\ref{table:v7.transmitter.tube}.
\begin{enumerate}
\item
Explain why the failures in the interval 0-25 days could be considered
to be left-censored observations.
\item
Explain why the failures in the interval 100-$\infty$ days are
right-censored observations.
\end{enumerate}
\end{exercise}

%-------------------------------------------------------------------
\begin{exercise}
Write down an expression for the likelihood of the V7 tube data in
Table \ref{table:v7.transmitter.tube}. Also give an explicit
expression for the constant term $\likeconstant$.
\end{exercise}

%-------------------------------------------------------------------
\begin{exercise}
\label{exercise:battery.censor.methods}
A test facility with 20 test positions is being used to conduct a life
test of a newly designed battery.  Each battery will be tested until
failure or until it has accumulated 100 charge/recharge cycles or
until it is taken off test for some other reason.  When a battery
fails, it will be replaced with a new unit, keeping the 20 test
positions busy. At several randomly occurring  
times during the test it will be necessary
to remove one or more unfailed units from test. The removed units will
be used for other experiments and demonstrations, but will not be
returned to the life test. Removed units will be treated as censored
observations (all that is known is that the unit did not fail
by the time the unit was removed from test). The following list
suggests some methods that might be used for choosing which battery to
remove from test.  For each method of choosing, explain whether the
censoring mechanism is ``fair'' or not (i.e., a censoring method that
will not lead to undue bias for making inferences about the
distribution of battery life). If it is a ``fair'' censoring method,
explain why the method might be better than the other suggested
methods (acknowledging that this would depend on the purpose of the
test). If the selection method will result in bias, explain the 
direction of the bias.
\begin{itemize}
\item
A battery selected at random.
\item
The battery with the most running time.
\item
The battery with the least running time.
\item
The battery with the lowest measured capacity (as measured
at the end of each cycle).
\end{itemize}
\end{exercise}

%-------------------------------------------------------------------
\begin{exercise}
Consider the life test described in
Exercise~\ref{exercise:battery.censor.methods}.
Generally, experimenters would want to
assume that there would be no differences
among the 20 test positions. Describe the consequences of 
incorrectly making such
an assumption and how one could detect such differences
and/or protect against such consequences.
\end{exercise}

%-------------------------------------------------------------------
\begin{exercise1}
Show that the pdf, cdf, survival, hazard, and cumulative hazard are
mathematically equivalent descriptions of a continuous distribution
in the sense that given any of these functions the other four are
completely determined.
\end{exercise1}


%-------------------------------------------------------------------
\begin{exercise1}
Consider the setting given in
Section~\ref{section:model.for.discrete.data}.  
\begin{enumerate}
\item 
Prove that equation (\ref{equation:pvec.def}) is true.
\item 
Show that
\begin{eqnarray*}
\pi_{1}&=&p_{1}  \\
\pi_{i}&=&p_{i} \prod_{j=1}^{i-1}\left [ 1 - p_{j} \right ], \,\,\, i=2, \cdots, m \\
\pi_{m+1}&=&\prod_{j=1}^{m}\left [ 1 - p_{j} \right ].
\end{eqnarray*}
\item 
Provide an argument to show that if
$\pi_{1} > 0, \ldots,\pi_{m+1} > 0$, then $0 < p_{i} < 1$
is the only restriction on the $p_{i}$ values for $i=1,\dots , m$.  
\item 
Prove that equation~(\ref{equation:discrete.survival.function}) is
true.
\end{enumerate}
\end{exercise1}


%-------------------------------------------------------------------

\begin{exercise1}
Consider the special case of (\ref{equation:like.censoring.in.interval})
where
$f_{C}(\realrv)$ is a probability mass function
assigning all of its probability to points $t_{i}~(i=1,\ldots,m)$.
\begin{enumerate}
\item
Show, in this case, that (\ref{equation:like.censoring.in.interval})
reduces to
\begin{eqnarray*}
\like_{i}(\pvec;\data_{i})&=&
\left \{ \left [
         F(\realrv_{i})-F(\realrv_{i-1})
	 \right ]
          \left [
	   1-F_{C}(\realrv_{i-1})
	  \right ] 
\right \}^{d_{i}}
\times 
 \left \{
   f_C(\realrv_{i}) \left [
	   1-F(\realrv_{i})
	  \right ]
\right \}^{r_{i}}
\\
&=&
\left [
   f_C(\realrv_{i}) 
\right ]^{r_{i}}
   \left [
	   1-F_{C}(\realrv_{i-1})
	  \right ] ^{d_{i}}
\times 
\left [ 
  F(\realrv_{i})-F(\realrv_{i-1})
\right ]^{d_{i}}
 \left [
	   1-F(\realrv_{i})
	  \right ]^{r_{i}}.
\end{eqnarray*}
\item
Give conditions under which parts of this likelihood term
$\like_{i}(\pvec;\data_{i})$ can be absorbed into the likelihood
constant $\likeconstant$ so that this likelihood term will correspond
to the $\like_{i}(\pvec;\data_{i})$ in
(\ref{equation:like.group.censoring}).
\end{enumerate}
\end{exercise1}

%-------------------------------------------------------------------
\begin{exercise1}
\label{exercise:F.of.T.dist}
If a continuous random variable $\rv$ has a cdf $F(t)=\Pr(\rv \leq
t)$, then it is easy to show that the transformed random variable
$F(T)$ follows a 0--1 uniform distribution. A similar property for
random variables is that the cumulative hazard transformation $H(T)$
follows an exponential distribution. Show this.
\end{exercise1}


