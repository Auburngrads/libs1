%chapter 21
%original by wqmeeker  3 aug 1994
%original by wqmeeker  26 may 1995 material from old papers
%edited by driker 19 dec 96
%edited by driker 7 apr 97
\setcounter{chapter}{20}

%\setcounter{page}{m}

\chapter{Accelerated Degradation Tests}
\label{chapter:accelerated.degradation}

\input{\chapterhome/common_heading.tex}

%----------------------------------------------------------------------
%----------------------------------------------------------------------
\section*{Objectives}
This chapter explains
\begin{itemize} 
\item 
How accelerated degradation tests
can be used to assess and improve product reliability.
\item 
Models for accelerated degradation tests.
\item 
How to analyze accelerated degradation data.
\item 
How accelerated degradation test methods compare
with traditional accelerated life test methods.
\item 
A simple approximate method that can be used for some accelerated
degradation data analyses.
\end{itemize}
%----------------------------------------------------------------------
%----------------------------------------------------------------------
\section*{Overview}

This chapter explains and illustrates the use of acceleration models
from Chapter~\ref{chapter:accelerated.test.models} with the
degradation analysis methods in
Chapter~\ref{chapter:degradation.data}.  Both of these chapters are
important in the understanding of the material in this chapter.  The
comparison of accelerated degradation tests with accelerated life
tests also depends on the material in
Chapter~\ref{chapter:analyzing.alt.data}.
Section~\ref{section:adt.models} introduces an example and describes
a model for accelerated degradation data.
Section~\ref{section:adt.estimation} shows how to estimate the
parameters of this model.  Section~\ref{section:adt.est.functions}
applies methods from Section~\ref{section:est.ft} to estimate the
failure-time distribution corresponding to the degradation model.
Section~\ref{section:adt.bootstrap} shows how to apply the methods
in Section~\ref{section:degrad.ci} to obtain bootstrap confidence
intervals for a failure-time distribution.
Section~\ref{section:adt.compare.alt} compares the accelerated
degradation analysis for the example with a corresponding
accelerated life test analysis.
Section~\ref{section:app.acc.deg.anal} describes and illustrates the
use of a simpler approximate method for accelerated degradation
analysis.
%----------------------------------------------------------------------
%----------------------------------------------------------------------
\section{Introduction}
The degradation analysis methods described in
Chapter~\ref{chapter:degradation.data} can provide useful
information for reliability studies, even when failures are not
observed.  For some products, however, degradation rates at use
conditions are so low that appreciable degradation will not be
observed during usual tests. In such cases, it might be possible to
accelerate the degradation process. For example, raising temperature
will often accelerate the rate of a chemical degradation process.

\begin{example}
\label{example:device-b.degradation.data}
{\bf Device-B power output degradation.}
Figure~\ref{figure:device.b.degradation.data.ps} shows the decrease
in power, over time, for a sample of integrated circuit devices
called ``Device-B.''  Samples of devices were tested at each of
three levels of junction temperature. Based on a life test lasting about
6 months, design engineers needed an assessment of the proportion of
these devices that would ``fail'' before 15 years (about 130 thousand
hours) of operation at 80$\degreesc$. This assessment would be used
to determine the amount of redundancy required in the full system.
Failure for an individual device was defined as power output more
than .5 decibels (dB) below initial output. At standard operating
temperatures (e.g., $80 \degreesc$), the devices will degrade too
slowly to provide useful information in 6 months.  Because units at
low temperature degrade more slowly, they had to be run for longer
periods of time to accumulate appreciable degradation.  Because of
severe limitations in the number of test positions, fewer units were
run at lower temperatures. The original data from this experiment
are proprietary. The data shown in
Figure~\ref{figure:device.b.degradation.data.ps} were actually
simulated from a model suggested by limited real data available at
the time the more complete experiment was being planned.
%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/device.b.degradation.data.ps} 
\caption{Accelerated degradation test results
giving power drop in Device-B output for a sample of units tested at
three levels of junction temperature.}
\label{figure:device.b.degradation.data.ps}
\end{figure}
%-------------------------------------------------------------------
\end{example}

%----------------------------------------------------------------------
%----------------------------------------------------------------------
\section{Models for Accelerated Degradation Test Data}
\label{section:adt.models}
Section~\ref{section:degrad.models} presents models for degradation
data. Generally these models describe the behavior, over time, of a
particular degradation or product performance measure (such as crack
size, resistance, or power output) as well as 
the unit-to-unit variability in degradation paths. 
For accelerated degradation data, the model also describes the
relationship between degradation or performance and the accelerating
variable or variables (e.g., voltage or temperature).

As in Chapter~\ref{chapter:degradation.data}, the observed sample
degradation $y_{ij}$ of unit $i$ at time $t_{ij}$ is a unit's actual
degradation plus measurement error and is given by
\begin{equation}
\label{equation:adt.deg.path.model}
y_{ij} = \degpath_{ij} + \epsilon_{ij},\quad i
= 1, \dots, n, \quad j = 1, \dots, m_{i}
\end{equation}
where $\degpath_{ij}=\degpath(t_{ij},\beta_{1i},\dots,\beta_{ki})$ 
is the actual
path of the unit $i$ at time $t_{ij}$ (the times need not be the
same for all units) and $\epsilon_{ij}\sim \NOR
\left(0,\sigma_{\epsilon}\right)$ is a residual deviation
for unit $i$ at time $t_j$. The
total number of inspections on unit $i$ is denoted by $m_{i}$.
Typically, a path model will have $k=1$, 2, 3, or 4 parameters.
As described in Section~\ref{section:models.for.variation}, some of
the $\beta_{1},
\dots,\beta_{k}$ parameters will be random from unit to unit.  One or
more of the $\beta_{1},
\dots,\beta_{k}$ parameters could, however, be modeled as
common across all units.

The simple chemical degradation path model
from Example~\ref{example:concave.deg}, rewritten in the generic
notation and with a temperature acceleration variable affecting the
rate of the reaction is
\begin{equation}
\label{equation:nonlinear.deg.path}
\degpath(t;\Temp) = \degpath_{\infty} \times
\left \{1 -  \exp \left [-\Rate_{U} \times 
\AF(\Temp) \times t \right ] \right \}.
\end{equation}
Here $\Rate_{U}$ is the rate reaction at use temperature
$\Temp_{U}$, $\Rate_{U} \times \AF(\Temp)$ is the rate reaction at
temperature $\Temp$, and $\degpath_{\infty}$ is the asymptote.  For
$\degpath_{\infty} < 0$, we specify that failure occurs at the
smallest $t$ such that $\degpath(t) < \critdeg$.

Following from 
(\ref{equation:arrhenius.af}), the 
Arrhenius acceleration factor 
\begin{equation}
\label{equation:adt.arrhenius.af}
\AF(\Temp,\Temp_{U},\Ea) = \exp\left[
\Ea\left( \frac{11605}{\Temp_{U}+273.15} -  \frac{11605}{\Temp+273.15}
 \right) \right]
\end{equation}
depends only on the two temperature levels and the activation energy $\Ea$.
If $\Temp > \Temp_{U}$, then $\AF(\Temp,\Temp_{U},\Ea) > 1$.
For simplicity, we use the notation
$\AF(\Temp)=\AF(\Temp,\Temp_{U},\Ea)$ when
$\Temp_{U}$ and $\Ea$ are understood to be, respectively, product use
(or other specified
base line) temperature and a reaction-specific activation energy.

\subsection{Accelerated degradation model parameters}

In general, rate-acceleration parameters are unknown
fixed-effect parameters (e.g., the Arrhenius model suggests no
unit-to-unit variability in activation energy).  As described in
Section~\ref{section:general.degradation.model}, fixed-effect
parameters are included, notationally, in the parameter vector
$\vecofbetas$ introduced in Section~\ref{section:general.degradation.model}. 
Thus for the single-step chemical reaction models in 
Sections~\ref{section:nonlin.deg.acc} and
\ref{section:linear.degradation}, we have one additional parameter to
estimate. The total number of parameters in $\vecofbetas$ 
is still denoted by $k$.

The values of $\vecofbetas$ corresponding to an individual
unit may be of interest in some applications (e.g., predict the
future degradation of a particular unit, based on a few early
readings). Subsequent development in this chapter, however, will
concentrate on the use of degradation data to make inferences about
the population or process from which the sample units were obtained or
predictions about the life distribution of a population of units 
at specific levels of the accelerating variable (e.g., temperature). In this
case, the underlying model parameters are $\muvec_{\betavec}$ and
$\vcvmat_{\betavec}$, as well as the residual standard deviation
$\sigma_{\epsilon}$.  Again, the appropriate rows and columns in
$\vcvmat_{\betavec}$, corresponding to the fixed parameters in
$\vecofbetas$, contain $0$'s. For shorthand, we will use
$\thetavec_{\betavec}=(\muvec_{\betavec},\vcvmat_{\betavec})$ to denote
the parameters of the overall degradation population or process.

\begin{example}{\bf Device-B power output degradation model
parameterization.}
\label{example:device.b.parameterization}
For the Device-B power-drop data in 
Example~\ref{example:device-b.degradation.data}, 
the scientists responsible for
the product were confident that degradation was caused by a simple
one-step chemical reaction that could be described by the model in
Example~\ref{example:concave.deg}. Thus for the data in
Figure~\ref{figure:device.b.degradation.data.ps}, we will use the
accelerated degradation model in (\ref{equation:nonlinear.deg.path}),
assuming that $\Rate_{U}$ and $\degpath_{\infty}$ are random from
unit to unit.  Then a possible parameterization would be
$(\beta_{1},\beta_{2},\beta_{3}) =
[\log(\Rate_{U}),\log(-\degpath_{\infty}),\Ea]$ where the first two
parameters are random effects and the activation energy $\Ea$ is a fixed
effect.  That is, $\Ea$ is regarded as a material property that does
not depend on temperature and that is constant from unit to unit.
\end{example}

%----------------------------------------------------------------------
%----------------------------------------------------------------------
\section{Estimating Accelerated Degradation Test Model Parameters}
\label{section:adt.estimation}
The likelihood for the random-parameter degradation model is the same
as that given in (\ref{equation:degradation.likelihood}) and the
methods of estimation described there can be applied directly to the
accelerated degradation model.

\begin{example}{\bf Estimates of the Device-B model parameters.}
\label{example:device.b.basic.estimate}
Continuing with Example~\ref{example:device.b.parameterization}, we
fit the mixed-effect model (\ref{equation:nonlinear.deg.path}) to the
Device-B data. In order to improve the stability and robustness of the
approximate ML algorithm, it is important to keep the correlation
between the estimates of $\Ea$ and the parameters relating to 
reaction rate $\Rate$
small. This can be done by estimating the distribution of $\Rate$ at
some stress that is central to the experimental temperatures, rather
than the use-temperature. Thus we parameterize with
$\beta_{1}=\log[\Rate(195)]$, $\beta_{2}=\log(-\degpath_{\infty})$,
and $\beta_{3}=\Ea$ where $\Rate(195)=\Rate_{U} \times \AF(195)$ is
the reaction rate at $195
\degreesc$. Our model uses a bivariate normal distribution to describe
unit-to-unit variability in $(\beta_{1},\beta_{2})$. Also, activation
energy $\beta_{3}=\Ea$ is a constant, but unknown, material property.
The nonlinear mixed effects computer program of Pinheiro and Bates~(1995b) 
gives the following approximate ML estimates of the model parameters
%%%      basic.adt.param(mmic2.boot.setup$nlme.out)
%% %          A        C         B                                
%%     0.3510307 0.666951 -7.571962 0.01808637 -0.02918465 0.1502104 0.02328177
\begin{equation} 
\label{equation:deviceb.mles} 
\muvechat_{\betavec} =
\left( 
\begin{array}{r}  -7.572 \\ .3510\\ .6670
\end{array}
\right), \qquad
\vcvmathat_{\betavec} =
\left( 
\begin{array}{rrr}
     .15021  & -.02918 & 0\\
    -.02918  &  .01809 & 0\\
      0      &   0     & 0
\end{array} 
\right)
\end{equation} 
and $ \sigmahat_{\epsilon}=.0233 $.  The lines in
Figure~\ref{figure:device.b.m2.fit.ps} show the fitted
model~(\ref{equation:nonlinear.deg.path}) for each of the sample
paths (indicated by the points on the plot) for the Device-B
degradation data.  Figure~\ref{figure:device.b.m2.data.bvn.ps} plots
the estimates of the $\beta_{1}$ and $\beta_{2}$ parameters for each
of the 34 sample paths, indicating the reasonableness of the
bivariate normal distribution model for this random-coefficient
model.
%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/device.b.m2.fit.ps}
\caption{Device-B power drop observations and fitted degradation model
for the 34 sample paths.}
\label{figure:device.b.m2.fit.ps}
\end{figure}
%-------------------------------------------------------------------
%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/device.b.m2.data.bvn.ps}
\caption{Plot of $\betahat_{1i}$ 
versus $\betahat_{2i}$ for the $i=1,\dots, 34$ sample paths from
Device-B, also showing contours corresponding to the fitted
bivariate normal distribution. The $+$ marks the estimates of the
means $\mu_{\beta_{1}}$ and $\mu_{\beta_{2}}$.}
\label{figure:device.b.m2.data.bvn.ps}
\end{figure}
%-------------------------------------------------------------------
\end{example}

%--------------------------------------------------------------------------
%--------------------------------------------------------------------------

%----------------------------------------------------------------------
%----------------------------------------------------------------------
\section{Estimation of Failure Probabilities, Distribution Quantiles,
and Other Functions of Model Parameters}
\label{section:adt.est.functions}
One can estimate the
failure-time distribution $F(t)$ by substituting the estimates
$\thetavechat_{\betavec}$ into (\ref{equation:mixed.effect.to.ttf}) giving
$\Fhat(t) = F(t; \thetavechat_{\betavec})$. 
This is straightforward when $F(t)$ can be expressed in
closed form.  When there is no closed-form expression for $F(t)$, and
when numerical transformation methods are too complicated, one can
use either Algorithm~\ref{algorithm:evaluation.of.f.of.t.by.int} or
\ref{algorithm:mc.evaluation.of.f.of.t}, to evaluate
(\ref{equation:mixed.effect.to.ttf}) at $\thetavechat_{\betavec}$.

\begin{example}{\bf Device-B degradation data estimate of $\boldsymbol{F(t)}$.}
\label{example:device.b.degradation.fhat}
Figure~\ref{figure:device.b.comp.deg.m2.cdf.ps}
%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/device.b.comp.deg.m2.cdf.ps}
\caption{Estimates of the Device-B failure-time distributions at 80, 100, 150,
and 195$\degreesc$, based on the degradation data.}
\label{figure:device.b.comp.deg.m2.cdf.ps}
\end{figure}
%-------------------------------------------------------------------
shows $\Fhat(t)$ for Device-B based on the power-drop data with
failure defined as a power drop of $\critdeg = -.5$ dB.  Estimates are
shown for $195$, $150$, $100$, and
$80\degreesc$.  These estimates were computed with
Algorithm~\ref{algorithm:evaluation.of.f.of.t.by.int}, using the
estimates of the model parameters
$\thetavechat_{\betavec}=(\muvechat_{\betavec},
\vcvmathat_{\betavec})$ 
from Example~\ref{example:device.b.basic.estimate}.
\end{example}

%----------------------------------------------------------------------
%----------------------------------------------------------------------
\section{Confidence Intervals Based on Bootstrap Samples}
\label{section:adt.bootstrap}

Because there is no simple method of computing standard errors for
$\Fhat(t)$, we use a simulation of the sampling/degradation process
and the bias-corrected percentile bootstrap method to obtain
parametric bootstrap confidence intervals for quantities of
interest. This method is described in
Section~\ref{section:percentile.bootstrap} and more fully in
Efron~(1985) and Efron and Tibshirani~(1993). The method is a
straightforward implementation of
Algorithm~\ref{algorithm:degradation.bootstrap}, described in
Section~\ref{section:degrad.ci}.

For a SAFT model, once $\Fhat^{*}(t)$ has been computed in step 4 of
Algorithm~\ref{algorithm:degradation.bootstrap} for one set of
accelerating variable conditions, it is possible to obtain
$\Fhat^{*}(t)$ for other accelerating variable conditions by simply
scaling times. Otherwise the bootstrap estimates from step 3 need to
be reused in step 4 to recompute the $\Fhat^{*}(t)$ values for each
new set of conditions.

%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/device.b.80.ci.cdf.ps}
\caption{Estimates of the Device-B failure-time distribution at 80$\degreesc$
with approximate 80\% and 90\% pointwise two-sided bootstrap
confidence intervals based on the power-drop data with failure defined
as a power drop of $\critdeg = -.5$dB.}
\label{figure:device.b.80.ci.cdf.ps}
\end{figure}
%-------------------------------------------------------------------

\begin{example}{\bf Degradation-data bootstrap 
	confidence intervals for the Device-B $\boldsymbol{F(t)}$ at
80$\degreesc$.}
\label{example:device.b.degradation.ci}
Continuing with Example~\ref{example:device.b.degradation.fhat},
Figure~\ref{figure:device.b.80.ci.cdf.ps} shows the point estimate and
a set of pointwise two-sided approximate 90\% and 80\% bootstrap
bias-corrected percentile confidence intervals for $F(t)$ at
$80\degreesc$, based on the IC power-drop data with failure defined as
a power drop of $\critdeg = -.5$dB. The bootstrap confidence intervals
were computed by using
Algorithm~\ref{algorithm:evaluation.of.f.of.t.by.int} and
Algorithm~\ref{algorithm:degradation.bootstrap} to evaluate
$\Fhat^{*}(t)$. Specifically, the point estimate for $F(t)$ at 130
thousand hours is .14 and the approximate 90\% confidence interval is
$[.005,\quad .64]$. The extremely wide interval is due to the small
number of units tested a 150$\degreesc$ and the large amount of
extrapolation required to estimate to $F(t)$ at 80$\degreesc$.  It is
important to recognize that this interval does not reflect possible
deviations from the assumed model.
\end{example}

%----------------------------------------------------------------------
%----------------------------------------------------------------------
\section{Comparison with Traditional Accelerated Life Test Methods}
\label{section:adt.compare.alt}

This section compares accelerated degradation and accelerated life
test analyses.  With failure defined as power drop below $-.5$ dB,
there were no failures at $150\degreesc$.  Although it is possible to
fit a model to the resulting failure-time data, the degree of extrapolation
with no failures at $150\degreesc$ would be, from a practical point of
view, unacceptable. The comparison will be useful for showing
one of the main advantages of degradation analysis---the ability to
use degradation data for units that have not failed. Degradation data provide
important information at lower levels of stress where few, if any,
failures will be observed, thus reducing the degree of extrapolation.

%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/device.b.alt.scatter.ps}
\caption{Scatter-plot of Device-B failure-time data
with failure defined as power drop below $-.5$ dB. The symbol $\Delta$
indicates the seven units that were tested at 150$\degreesc$ and had not
failed at the end of 4000 hours.}
\label{figure:device.b.alt.scatter.ps}
\end{figure}
%-------------------------------------------------------------------
Figure~\ref{figure:device.b.alt.scatter.ps} shows a scatter-plot of
the failure-time data. These failure-time data were
obtained from the degradation data in
Figure~\ref{figure:device.b.degradation.data.ps}. 
All seven units tested at 150$\degreesc$ were right censored.
Figure~\ref{figure:device.b.groupi.lognormal.ps} is a lognormal multiple
probability plot with the straight lines showing individual
lognormal distributions fitted to the samples at 237$\degreesc$ and
195$\degreesc$.
%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/device.b.groupi.lognormal.ps}
\caption{Individual lognormal probability 
plots of the Device-B failure-time data with failure defined as
power drop below $-.5$ dB.}
\label{figure:device.b.groupi.lognormal.ps}
\end{figure}
%-------------------------------------------------------------------
This figure shows that the lognormal distributions provide a good fit
at both temperatures.
Figure~\ref{figure:device.b.groupm.lognormal.ps} is also a lognormal multiple
probability plot for the individual samples at
237$\degreesc$ and 195$\degreesc$.
%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/device.b.groupm.lognormal.ps}
\caption{The lognormal-Arrhenius model fit to the Device-B failure-time
data with failure defined as power drop below $-.5$ dB.}
\label{figure:device.b.groupm.lognormal.ps}
\end{figure}
%-------------------------------------------------------------------
In this case, however, the superimposed lines show the fitted
lognormal-Arrhenius model
relating the failure-time distributions to temperature.
This is a commonly used accelerated life test model for electronic
components, as described in Chapters~\ref{chapter:accelerated.test.models} and 
\ref{chapter:analyzing.alt.data}. The
lognormal-Arrhenius model assumes that log failure time has a normal
distribution with mean
\begin{displaymath}
\mu = \beta_{0} + \beta_{3} \left(\frac{11605}{\Temp+273.15}\right)
\end{displaymath}
and constant standard deviation $\sigma$.  In relation to
the lognormal-Arrhenius failure-time model described in
Section~\ref{section:nonlin.deg.acc}, the slope $\beta_{3}=\Ea$
is the activation energy and the intercept is
\begin{displaymath}
\beta_{0}= \mu_{U} - \beta_{3} \left(\frac{11605}{\Temp_{U}+273.15}\right).
\end{displaymath}
The estimated failure-time lognormal cdfs in
Figure~\ref{figure:device.b.groupm.lognormal.ps} are parallel because
of the constant-$\sigma$ assumption. This plot shows some
deviations from the assumed model. These deviations, however, are
within what could be expected from random variability alone (a
likelihood ratio test comparing the model depicted in
Figure~\ref{figure:device.b.groupm.lognormal.ps} with independent ML
fits at each level of temperature, shown on
Figure~\ref{figure:device.b.groupi.lognormal.ps}, had a $p$-value of
.052).

Figure~\ref{figure:device.b.salt.lognormal.comp.ps} shows the same
lognormal-Arrhenius model fit given in
Figure~\ref{figure:device.b.groupm.lognormal.ps} with an extrapolated
estimate of the cdf at $80\degreesc$. 
%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/device.b.salt.lognormal.comp.ps}
\caption{Lognormal-Arrhenius model fit to the Device-B failure-time
data with failure defined as power drop below $-.5$ dB (solid lines)
compared with the corresponding degradation model estimates (dotted
lines).  Also shown is the set of pointwise approximate 90\%
confidence intervals for $F(t)$ at 80$\degreesc$ (dashed lines), based
on a bootstrap of the degradation analysis.}
\label{figure:device.b.salt.lognormal.comp.ps}
\end{figure}
%------------------------------------------------------------------- 
The dotted lines on this figure are the degradation-model-based
estimates of the failure-time distributions shown
in Figure~\ref{figure:device.b.comp.deg.m2.cdf.ps}.  There are small
differences between the lognormal and the degradation models at
237$\degreesc$ and 195$\degreesc$.  The differences at
150$\degreesc$ and 80$\degreesc$ have been amplified by
extrapolation. The degradation estimate would have more credibility
because it makes full use of the information available at
150$\degreesc$.

The overall close agreement between the degradation model and the lognormal
failure-time model can be explained by referring to the models
introduced in Section~\ref{section:nonlin.deg.acc}.  There we
showed that failure time will have a lognormal distribution if
${\rv}(\Temp_{U})=- \, (1/\Rate_{U})\log
\left(1-\critdeg/\degpath_{\infty} \right )$
has a lognormal distribution. In our degradation model,
$\log(\Rate_{U})$ and $\log(-\degpath_{\infty})$ [and thus
$\log(\critdeg/\degpath_{\infty})$] are assumed to have a joint
normal distribution. If $\critdeg/\degpath_{\infty}$ is small
relative to 1 (as in this example), then $ \log( 1-\critdeg /
\degpath_{\infty} )
\approx -\critdeg / \degpath_{\infty} $ and thus $ \rv ( \Temp_{U} )$  is
approximately the ratio of two lognormal random variables, and the
ratio of two lognormal random variables also has a lognormal
distribution.

Figure~\ref{figure:device.b.salt.weibull.comp.ps} is similar to
Figure~\ref{figure:device.b.salt.lognormal.comp.ps} with a fitted
Weibull distribution for failure time.  Comparing
Figures~\ref{figure:device.b.salt.lognormal.comp.ps} and
\ref{figure:device.b.salt.weibull.comp.ps}, the lognormal ALT and 
degradation models provide a somewhat better fit to the data.  As
explained above and in
Section~\ref{section:lognormal.distribution.def}, experience and
physical theory also favor the lognormal distribution in this
application.

%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/device.b.salt.weibull.comp.ps}
\caption{The Weibull-Arrhenius model fit to the Device-B failure-time
data (solid lines) compared with the degradation-model estimates
(dotted lines).}
\label{figure:device.b.salt.weibull.comp.ps}
\end{figure}
%-------------------------------------------------------------------


%----------------------------------------------------------------------
\section{Approximate Accelerated Degradation Analysis}
\label{section:app.acc.deg.anal}
The simple method for degradation data analysis explained in
Section~\ref{section:app.deg.anal} extends directly to accelerated
degradation analysis. In particular, one can use the algorithm
described there to predict the failure time for each sample
path. Then these data can be analyzed using the methods from
Chapter~\ref{chapter:analyzing.alt.data}, as shown in the following
example.  It is important to remember, however, that such an
analysis has the same limitations described in
Section~\ref{section:app.deg.anal}.

\begin{example}
{\bf Sliding metal wear data analysis.}  
\label{example:sliding.wear.simple}
An experiment was conducted to test the wear resistance of a
particular metal alloy. The sliding test was conducted over a range
of different applied weights in order to study the effect of weight
and to gain a better understanding of the wear mechanism.  The data
are given in Appendix Table~\ref{atable:metal.wear.data}.
Figures~\ref{figure:metal.wear.ps} shows the resulting degradation
data.  The same data are given in
Figure~\ref{figure:log.metal.wear.ps}, plotted on log-log axes. The
predicted pseudo failure times were obtained by using ordinary least
squares to fit a line through each sample path on the log-log scale
(Figure~\ref{figure:log.metal.wear.ps}) and extrapolating to the
time at which the scar width would be 50 microns.
%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/metal.wear.ps}
\caption{Scar width resulting from a
metal-to-metal sliding test for different applied weights.}
\label{figure:metal.wear.ps}
\end{figure}
%-------------------------------------------------------------------
%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/log.metal.wear.ps}
\caption{Scar width resulting from a
metal-to-metal sliding test for different applied weights (using
log-log axes).}
\label{figure:log.metal.wear.ps}
\end{figure}
%-------------------------------------------------------------------
These predicted pseudo failure times are given in
Table~\ref{table:metal.wear.pseudo.times}.
Figure~\ref{figure:etal.wear.altplot.ps} plots the pseudo failure
times (on a log axis) versus applied weight. This plot also
shows a fitted
linear relationship between time to 50 microns and applied
weight. The variability at 100 grams is much smaller than at the
other two weights, but with the small sample sizes involved, it is
possible that this could be due to variability in the data.
%------------------------------------------------------------------- 
\begin{table}
\caption{Metal-wear ``failure'' times in hours.}
\centering\small
\begin{tabular}{*{5}{r}}
\\[-.5ex]
\hline
Grams & \multicolumn{4} {c} {Pseudo Failure times}\\
\hline
100 & 724  & 718 &  659  & 677 \\
50  & 3216 & 1729 & 2234 & 1689  \\
10 & 3981 & 4600 & 5718 & 4487  \\
\hline
\end{tabular}\\
\begin{minipage}[t]{4in}
\end{minipage}
\label{table:metal.wear.pseudo.times}
\end{table}
%-------------------------------------------------------------------
%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/metal.wear.altplot.ps}
\caption{Pseudo failure times to 50 microns scar width
versus applied weight for the
metal-to-metal sliding test.}
\label{figure:etal.wear.altplot.ps}
\end{figure}
%-------------------------------------------------------------------
Figure~\ref{figure:metal.wear.groupi.lognor.ps} is a lognormal
probability plot for the data at the three different levels of
weight. The plot shows the smaller amount of variability at 100
grams (indicated by the steeper slope in the fitted line). The
lognormal distribution fits quite well at all levels of
weight (the normal and Weibull distributions did not fit as
well as the lognormal distribution).
%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/metal.wear.groupi.lognor.ps}
\caption{Lognormal probability plot showing the ML estimates of
time to 50 microns width for each weight.}
\label{figure:metal.wear.groupi.lognor.ps}
\end{figure}
%-------------------------------------------------------------------
Figure~\ref{figure:metal.wear.groupm.lognor.ps} is a lognormal
probability plot depicting the lognormal regression model.
Looking at the points relative to the fitted model suggests that
this is a plausible model for the data. However, because the model
is purely empirical, it would be risky to extrapolate to lower
levels of weight.
%-------------------------------------------------------------------
\begin{figure}
\splusbookfigure{\figurehome/metal.wear.groupm.lognor.ps}
\caption{Lognormal probability plot showing the lognormal
regression model ML estimates of time to 50 microns width for each
weight.}
\label{figure:metal.wear.groupm.lognor.ps}
\end{figure}
%-------------------------------------------------------------------
\end{example}
%----------------------------------------------------------------------
%----------------------------------------------------------------------
\section*{Bibliographic Notes}
Much of the material in this chapter has been taken from Meeker,
Escobar, and Lu~(1998).  Overall, the literature describing the
application of accelerated degradation methods is limited.  The
following is a brief summary of some available references.
Beckwith~(1979, 1980) describes methods of evaluating the decrease
in strength of an adhesive over time. Amster and Hooper~(1983)
propose a simple degradation model for single-, multiple-, and
step-stress life tests.  They show how to use this model to estimate
the central tendency of the failure-time distribution.  Lu and
Pantula~(1989) use a repeated-measures model to analyze accelerated
test degradation data from silicon devices.  Nelson~(1981) and
Nelson~(1990a, Chap.\ 11) reviews the degradation literature,
surveys applications, describes basic ideas on accelerated test
degradation models, and, using a specific example, shows how to
analyze degradation data with only one degradation reading per unit.
Carey and Tortorella~(1988) describe a Markov process model for
degradation data and give methods of estimating parameters and
testing goodness of fit.  Similar results are given in Carey~(1989).
Carey and Koenig~(1991) describe an application of the Carey and
Tortorella~(1988) methods of accelerated degradation analysis in the
assessment of the reliability of a logic devices that are components
in a new generation of submarine cables.  Chan, Boulanger, and
Tortorella~(1994) illustrate the use of some simple linear
regression methods for analyzing degradation data.  Tobias and
Trindade~(1995) use similar methods.

Murray~(1993, 1994) and Murray and Maekawa~(1996) describe
accelerated degradation test data for data-storage disk error
rates. These authors, Carey and Tortorella~(1988) and Tobias and
Trindade~(1995) use the approximate analysis method described in
Section~\ref{section:app.acc.deg.anal} to analyze their degradation
data. Tseng and Wen~(1997) describe the use of step-stress ADTs for
assessing the reliability of light-emitting diodes
(LEDs). Chang~(1992) analyzes ADT data from a test on power
supplies.

Boulanger and Escobar~(1994) describe methods for planning
accelerated degradation tests for an important class of degradation
models.  Chow and Liu~(1995, Chapter 9) describe applications of
accelerated degradation testing for estimating the shelf life of
pharmaceuticals.
\section*{Exercises}


\begin{exercise}
\label{exercise:resist.deg.data}
Appendix Table~\ref{atable:resistance.degradation.data} gives ADT
data on the increase in resistance over time of carbon-film
resistors tested at three different levels of temperature.  Suppose
that failure is defined as the time at which the resistance has
increased by 5\%. Use the approximate method of analysis described
in Sections~\ref{section:app.deg.anal} and
\ref{section:app.acc.deg.anal} to analyze these data. In particular,
\begin{enumerate}
\item
Make a plot the degradation versus time for each of the sample
paths.  Use both log and linear axes.
\item
Choose an appropriate transformation scale for the data to make the
paths approximately linear. Fit a separate linear regression model
to the appropriate subset of the data in each sample path. Plot the
estimated regression estimates in various ways.
\item
Explain the interpretation of the parameters of the regression model for
the individual paths. In what sense are these regression parameters
random?
\item
\label{exer.part:resist.deg.model}
Compute the average of the slope estimates within each temperature
group.  Plot these averages versus $11605/(\Tempc{} + 273.15)$ (or,
equivalently, plot on Arrhenius scales, as described in
Exercise~\ref{exercise:arrhenius.scale}). Assess the adequacy of a
linear relationship. What measure could you use, in an informal way,
to help in this assessment?
\item
Write down the temperature/degradation model implied by the
relationship graphed in part~\ref{exer.part:resist.deg.model}. Obtain
a graphical estimate of the activation energy for this degradation
process.
\item
Compute pseudo failure time for each of the sample paths and use
these to do a life data analysis and to estimate the failure-time
distribution at 50$\degreesc$.
\end{enumerate}
\end{exercise}

\begin{exercise}
Refer to Example~\ref{example:sliding.wear.simple}.  
\begin{enumerate}
\item
\label{exerpart:5microns}
Repeat the analysis using 30 microns as the definition of failure.
\item
\label{exerpart:500microns}
Repeat the analysis using 100 microns as the definition of failure.
\item
Compare the results in parts 
\ref{exerpart:5microns} and \ref{exerpart:500microns}. Comment on the
differences in assumptions needed to estimate these two different
distributions.
\end{enumerate}
\end{exercise}

\begin{exercise2}
Refer to Example~\ref{example:sliding.wear.simple}.  Repeat the
analysis using the approximate ML method like that used in
Examples~\ref{example:device.b.parameterization} through
\ref{example:device.b.degradation.ci}. Explain the
reason(s) for any differences in the analyses.
\end{exercise2}

\begin{exercise}
When iterative techniques are used for maximum likelihood estimation,
there is always some chance that the iterations will not converge to
the actual maximum.  As described in
Section~\ref{section:numerical.methods}, two precautions that will
improve the probability of success are to use a parameterization that
does not result in highly correlated parameter estimates and to have
good starting values for the iterations. In most cases, the best way
to get good starting values is to find simple graphical or
moment-based estimates (e.g., estimates based on sample means and
variances).  For the accelerated degradation model described by
(\ref{equation:nonlinear.deg.path}) and
(\ref{equation:adt.arrhenius.af}), and the corresponding data from
Example~\ref{example:device-b.degradation.data}, suggest expressions
that can be used to obtain starting values for the approximate ML
estimation algorithm.
\end{exercise}

\begin{exercise}
The relationship graphed in
Exercise~\ref{exercise:resist.deg.data}\ref{exer.part:resist.deg.model}
seems to provide an adequate description of the available
data. Describe the risks of using these data to predict life at
lower levels of temperature.
\end{exercise}

\begin{exercise}
\label{exercise:ber.adt.deg.data}
Extend the analysis done in
Exercise~\ref{exercise:block.error.rate.degradation.data}.  The
block error rate data were obtained by testing at higher than usual
conditions. Suppose that the activation energy for the degradation
process in $\Ea=.9$. Use this to obtain an estimate of disk life at
50$\degreesc$ and 85\% relative humidity.
\end{exercise}

%----------------------------------------------------------------------
\begin{exercise}
An alternative to the simple graphical/ordinary least squares
estimation method described in
Exercise~\ref{exercise:resist.deg.data} is to do ``full maximum
likelihood'' (or a close approximation to full ML), as described in
Section~\ref{section:est.degrad.param} and illustrated in
Examples~\ref{example:device.b.parameterization} through
\ref{example:device.b.degradation.ci}.  Explain the
reason(s) for any differences in the analyses.  Explain the
trade-offs between these two different approaches.
\end{exercise}


%----------------------------------------------------------------------
\begin{exercise}
Refer to the data in Appendix Table~\ref{atable:metal.wear.data},
also used in Example~\ref{example:sliding.wear.simple}. Data were
collected by testing four specimens at three different levels of
applied weight (10, 50, and 100 grams). Scar depth was measured at
2, 5, 10, 20, 50, 100, 200, and 500 cycles. Comment on the practical
value and the potential cost of the additional information that
would be obtained by
\begin{enumerate}
\item
Sampling wear at $2,5,10,15,20,25, \dots, 495$, and $500$ cycles.
\item
Sampling wear at $2, 5, 10, 20, 50, 100,
200, 500, 1000, 2000$, and $5000$ cycles.
\item
Testing eight units each at 10, 50, and 100 grams, using the original
sampling rate in time.
\item
Testing three units each at 10, 30, 60, and 100 grams, using the original
sampling rate in time.
\item
Testing three units each at 5, 20, 40, and 50 grams, using the original
sampling rate in time.
\item
Testing  three units each at 20, 60, 200, and 400 grams, using the original
sampling rate in time.
\end{enumerate}
\end{exercise}


%----------------------------------------------------------------------
\begin{exercise}
Refer to Figure~\ref{figure:device.b.degradation.data.ps}.
Comment on the possible loss of information that would result from
using the censored time to failure data instead of the degradation
data to make inferences on the failure time distribution.
\end{exercise}

%----------------------------------------------------------------------
\begin{exercise}
It has sometimes been suggested that one can (or even should) use
degradation data to obtain failure-time (or crossing time) data to be
used in analysis. Is this a good thing to do?  What are the trade-offs?
How should one handle observations that have not yet crossed the
boundary, but are close?  Refer to the data in
Figure~\ref{figure:device.b.degradation.data.ps} to help formulate
your answer.
\end{exercise}

%----------------------------------------------------------------------
\begin{exercise}
\label{exercise:adt.sim}
Design a computer program that can be used to simulate the results of
an ADT experiment, using the model defined by
(\ref{equation:adt.deg.path.model}),
(\ref{equation:nonlinear.deg.path}), and
(\ref{equation:adt.arrhenius.af}).  Write down all of the needed
inputs. Then outline each step of the process, including the formulas
that you would use to generate the needed random numbers, assuming
that you have access to a uniform random number generator. Note that
there are two stages of randomness in this ``mixed-effect'' model.
\end{exercise}

%----------------------------------------------------------------------
\begin{exercise2}
\label{exercise:adt.sim.prog}
Use a programming language to implement the algorithm described in
Exercise~\ref{exercise:adt.sim}. This will be much simpler if you use a
high-level language like \splus, Matlab, or Gauss rather than a
low-level language like Fortran or C.  Test the program by using the
ML estimates in (\ref{equation:deviceb.mles}) to replace the model
parameters.  Plot the set of sample paths for simulated experiment.
Compare with the sample paths in
Figure~\ref{figure:device.b.degradation.data.ps}. Comment on the
results.
\end{exercise2}

%----------------------------------------------------------------------
\begin{exercise2}
\label{exercise:adt.sim.ml.prog}
If your simulation program for Exercise~\ref{exercise:adt.sim.prog}
is written in \splus (version 3.4 or later) you can use the {\tt
nlme()} function to compute approximate ML estimates of the
parameters of your simulated ADT experiments. Implement this along
with your data-simulation program. Again, test the program by using
the ML estimates in (\ref{equation:deviceb.mles}) to replace the
model parameters.  Repeat the simulation 100 times. Plot the
resulting estimates of the model parameters in various ways. Comment
on the results of this simulation.
\end{exercise2}

%----------------------------------------------------------------------
\begin{exercise}
Refer to Exercise~\ref{exercise:adt.sim}. Explain how you could use
such a simulation program to help plan an ADT like the one in
Example~\ref{example:device-b.degradation.data}.
\end{exercise}


\begin{exercise1}
Give a detailed justification of the claim made in
Section~\ref{section:adt.compare.alt} about the approximate
lognormal distribution of the random variable ${\rv}(\Temp_{U})=- \,
(1/\Rate_{U})\log
\left(1-\critdeg/\degpath_{\infty} \right )$.
\end{exercise1}
%----------------------------------------------------------------------
