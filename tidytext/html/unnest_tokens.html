<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Split a column into tokens using the tokenizers package</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for unnest_tokens {tidytext}"><tr><td>unnest_tokens {tidytext}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Split a column into tokens using the tokenizers package</h2>

<h3>Description</h3>

<p>Split a column into tokens using the tokenizers package, splitting the table
into one-token-per-row. This function supports non-standard evaluation through
the tidyeval framework.
</p>


<h3>Usage</h3>

<pre>
unnest_tokens(tbl, output, input, token = "words", format = c("text", "man",
  "latex", "html", "xml"), to_lower = TRUE, drop = TRUE, collapse = NULL,
  ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>tbl</code></td>
<td>
<p>A data frame</p>
</td></tr>
<tr valign="top"><td><code>output</code></td>
<td>
<p>Output column to be created as string or symbol.</p>
</td></tr>
<tr valign="top"><td><code>input</code></td>
<td>
<p>Input column that gets split as string or symbol.
</p>
<p>The output/input arguments are passed by expression and support
<a href="../../rlang/html/quasiquotation.html">quasiquotation</a>; you can unquote strings and symbols.</p>
</td></tr>
<tr valign="top"><td><code>token</code></td>
<td>
<p>Unit for tokenizing, or a custom tokenizing function. Built-in
options are &quot;words&quot; (default), &quot;characters&quot;, &quot;ngrams&quot;, &quot;skip_ngrams&quot;,
&quot;sentences&quot;, &quot;lines&quot;, &quot;paragraphs&quot;, and &quot;regex&quot;. If a function, should take
a character vector and return a list of character vectors of the same length.</p>
</td></tr>
<tr valign="top"><td><code>format</code></td>
<td>
<p>Either &quot;text&quot;, &quot;man&quot;, &quot;latex&quot;, &quot;html&quot;, or &quot;xml&quot;. If not text,
this uses the hunspell tokenizer, and can tokenize only by &quot;word&quot;</p>
</td></tr>
<tr valign="top"><td><code>to_lower</code></td>
<td>
<p>Whether to turn column lowercase.</p>
</td></tr>
<tr valign="top"><td><code>drop</code></td>
<td>
<p>Whether original input column should get dropped. Ignored
if the original input and new output column have the same name.</p>
</td></tr>
<tr valign="top"><td><code>collapse</code></td>
<td>
<p>Whether to combine text with newlines first in case tokens
(such as sentences or paragraphs) span multiple lines. If NULL, collapses
when token method is &quot;ngrams&quot;, &quot;skip_ngrams&quot;, &quot;sentences&quot;, &quot;lines&quot;,
&quot;paragraphs&quot;, or &quot;regex&quot;.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>Extra arguments passed on to the tokenizer, such as <code>n</code> and
<code>k</code> for &quot;ngrams&quot; and &quot;skip_ngrams&quot; or <code>pattern</code> for &quot;regex&quot;.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>If the unit for tokenizing is ngrams, skip_ngrams, sentences, lines,
paragraphs, or regex, the entire input will be collapsed together before
tokenizing.
</p>
<p>If format is anything other than &quot;text&quot;, this uses the
<code><a href="../../hunspell/html/hunspell_parse.html">hunspell_parse</a></code> tokenizer instead of the tokenizers package.
This does not yet have support for tokenizing by any unit other than words.
</p>


<h3>Examples</h3>

<pre>

library(dplyr)
library(janeaustenr)

d &lt;- data_frame(txt = prideprejudice)
d

d %&gt;%
  unnest_tokens(word, txt)

d %&gt;%
  unnest_tokens(sentence, txt, token = "sentences")

d %&gt;%
  unnest_tokens(ngram, txt, token = "ngrams", n = 2)

d %&gt;%
  unnest_tokens(ngram, txt, token = "skip_ngrams", n = 4, k = 2)

d %&gt;%
  unnest_tokens(chapter, txt, token = "regex", pattern = "Chapter [\\d]")

# custom function
d %&gt;%
  unnest_tokens(word, txt, token = stringr::str_split, pattern = " ")

# tokenize HTML
h &lt;- data_frame(row = 1:2,
                text = c("&lt;h1&gt;Text &lt;b&gt;is&lt;/b&gt;", "&lt;a href='example.com'&gt;here&lt;/a&gt;"))

h %&gt;%
  unnest_tokens(word, text, format = "html")

</pre>

<hr /><div style="text-align: center;">[Package <em>tidytext</em> version 0.1.6 <a href="00Index.html">Index</a>]</div>
</body></html>
