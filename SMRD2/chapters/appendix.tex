%appendix
%\batchmode
%original by wqmeeker  27 Jan 94
%edited by wqmeeker     7 Feb 94
%edited by driker       18 Mar 94
%edited by lae          18 Mar 94 (bring in the notation in)
%edited by wqmeeker     26 mar 94 changed notation
%edited by wqmeeker     27 mar 94 brought in lae reg cond
%edited by lae          30 mar 94 update notation list
%edited by wqm          19 nov 94 reordering
%edited by driker       22 nov 94
%edited by wqmeeker	22/25 nov 94
%edited by lae     	26 nov 94 update BISA, GOMA, etc.
%edited by lae          27/30 nov 94 luis new notation and more editing
%edited by lae          22 dec 94 add notation and modify delta method
%edited by wqmeeker     31 dec 94 broke into notation, atables, appendices
%edited by lae          04 jan 95 made changes suggested by Bill
%edited by lae          06 nov 96 organize in a more logical sequence
%edited by lae          01 dec 96 tune up for new version of book
%edited by lae          24 mar 97 make changes suggested by joseph lu
%edited by lae          08 apr 97 change k_{1} to r_{1}
%\setcounter{page}{m}
\chapter{Some Results from Statistical Theory}
This appendix provides some useful tools and results
from statistical theory. These tools facilitate the
justification and extension of much of the methodology in the
book. 
Section~\ref{asection:transformation.of.rv} gives the
basic theory on transformation of random variables that is 
used mainly in Chapters~\ref{chapter:ls.parametric.models},
\ref{chapter:other.parametric.models}, and 
\ref{chapter:singledist.bayes}.
Section~\ref{asection:delta.method} describes the ``delta method,''
a useful method to obtain expressions for approximate variances of a
function of random quantities as a function of the variances and
covariances of the function arguments.
Section~\ref{asection:likelihood.information.matrix} gives a precise
definition of expected and observed information matrices.
Section~\ref{asection:regularity.conditions} lists general
regularity conditions assumed in most of the book.
Section~\ref{asection:convergence.in.distribution} provides the
definition of convergence in distribution for random variables and
gives examples of its use in this book.
Section~\ref{asection:general.theory} outlines general theory for ML
estimation.
%----------------------------------------------------------------------
%----------------------------------------------------------------------
\section{Cdfs and Pdfs of Functions of Random Variables}
\label{asection:transformation.of.rv}
This section shows how to obtain expressions for the
pdf and cdf of functions of random variables.
Let $\Uvec$ be a $k$-dimensional continuous
random vector with pdf $f_{\Uvec}(\uvec)$. We consider a 
$k$-dimensional transformation $\Vvec=\gvec(\Uvec)$
with the following properties:
\begin{enumerate}
\item 
The function $\vvec=\gvec(\uvec)=
[g_{1}(\uvec), \ldots, g_{k}(\uvec)]$
is a one-to-one transformation.
\item
The inverse function $\uvec=\gvec^{-1}(\vvec)=[g_{1}^{-1}(\vvec), \ldots, g_{k}^{-1}(\vvec)]$ has
continuous first partial derivatives with respect to $\vvec$.
\item
The Jacobian $J(\vvec)$ of $\gvec^{-1}(\vvec)$
is nonzero, where 
\begin{eqnarray*}
J(\vvec)&=&\det
\left |
\begin{array}{ccc}
\frac{ \partial g^{-1}_{1}(\vvec)}
     { \partial v_{1}} & \ldots & 
\frac{ \partial g^{-1}_{k}(\vvec)}
     { \partial v_{1}} 
\\
\vdots & \vdots & \vdots
\\
\frac{ \partial g^{-1}_{1}(\vvec)}
     { \partial v_{k}} & \ldots & 
\frac{ \partial g^{-1}_{k}(\vvec)}
     { \partial v_{k}} 
\end{array}
\right |.
\end{eqnarray*}
\end{enumerate}
Then the  pdf and cdf of $\Vvec$ are
\begin{eqnarray*}
f_{\Vvec}(\vvec)&=& f_{\Uvec}\,[\gvec^{-1}(\vvec)]
 \left | J(\vvec) \right |
\\
F_{\Vvec}(\vvec)&=& 
\int_{\xvec \, \le \, \vvec}
f_{\Uvec}\,[\gvec^{-1}(\xvec)] \left | J(\xvec) \right |
d \xvec.
\end{eqnarray*}
For the scalar case (i.e., $k=1$) the formulas
simplify to 
\begin{eqnarray*}
f_{V}(v)&=& f_{U}[g^{-1}(v)] \left | \frac{
 		d g^{-1}(v)
			       }
	                       {
		d v
			       } \right |
\\
F_{V}(v)&=& 
\int_{-\infty}^{v}
f_{U}[g^{-1}(x)] \left | \frac{
 		d g^{-1}(x)
			       }
	                       {
		d x
			       } \right |
d x
\\
&=&
\left \{
\begin{array}{lc}
F_{U} \left [ 
   g^{-1}(v)
      \right ]
& \quad  \mbox{if $g$ is increasing}
\\[.5ex]
1-F_{U} \left [ 
   g^{-1}(v)
      \right ]
& \quad  \mbox{if $g$ is decreasing}.
\end{array}
\right.
\end{eqnarray*}
For illustration, consider the following special cases:
\begin{enumerate}
\item
A one-dimensional transformation (i.e.,
$k=1$).
Let $U\sim \NOR(\mu,\, \sigma)$ and
consider the transformation $V=\exp(U)$.
Then
\begin{displaymath}
f_{U}(u)=\frac{1}{\sigma} \, 
  \phi_{\nor} \left (
	 \frac{u-\mu}
	      {\sigma}
              \right ), \quad -\infty< u < \infty,
\end{displaymath}
and $g(u)=\exp(u)$ which 
implies that $g^{-1}(v)=\log(v)$. Consequently,
$J(v)=1/v$  and
\begin{eqnarray*}
f_{V}(v)&=&\frac{1}{v} f_{U}[\log(v)]
=\frac{1}{v \sigma} \, 
  \phi_{\nor} \left [
	 \frac{\log(v)-\mu}
	      {\sigma}
              \right ], \quad v>0.
\\
F_{V}(v)&=&\int_{0}^{v}\frac{1}{x  \sigma} \, 
  \phi_{\nor} \left [
	 \frac{\log(x)-\mu}
	      {\sigma}
              \right ] dx
=\Phi_{\nor}
    \left [
   \frac{
    \log(v)-\mu
	}
	{
\sigma
        }
    \right ], \quad v>0.
\end{eqnarray*}
Note that $V$ has a $\LOGNOR(\mu,\sigma)$ 
distribution and
in the notation of 
Chapter~\ref{chapter:singledist.bayes}, 
$f(v)=(1/v)
f[\log(v)]$.
\item
A bivariate transformation
(i.e., $k=2$).
Let $\Uvec=(U_{1}, U_{2})$,
where $U_{1}$ and $U_{2}$ are independent,
$U_{1} \sim \UNIF[ \log(a_{1}), \log(b_{1})]$,
and 
$U_{2} \sim \NOR(a_{0}, b_{0})$.
Consider finding the distribution of
$\Vvec=(V_{1}, V_{2})=
[U_{1}- \Phi^{-1}_{\sev}(p) \exp (U_{2}), \,\,
\exp(U_{2})]$.

In view of the independence of
$U_{1}$ and $U_{2}$
\begin{displaymath}
f_{\Uvec}(u_{1}, u_{2})= \frac{ 1 	 } 	 
         { \log(b_{1}/a_{1}) 	 } 	\times 
\frac{1}
     {b_{0} }
\phi_{\nor} \left [
       \frac{
       u_{2}-a_{0}	        
            }
            {
                    b_{0}            
            }
            \right ]
\end{displaymath}
where
$\log(a_{1}) \le u_{1} \le \log(b_{1})$
and $-\infty < u_{2} < \infty$.

Using $\vvec=(v_{1}, v_{2})$, 
direct computations give 
$g_{1}^{-1}(\vvec)=
v_{1}+\Phi^{-1}_{\sev}(p)v_{2}$, $g_{2}^{-1}(\vvec)=\log(v_{2})$ and
$J(\vvec)=1/v_{2}$. Thus
\begin{eqnarray*}
f_{\Vvec}(v_{1}, v_{2})&=&
\frac{ 1 	 } 	 
         {\log(b_{1}/a_{1}) 	 } 	\times 
\frac{
     1
     }
     {
v_{2} \, b_{0}
     }
\phi_{\nor} 		 
\left [
\frac{
\log(v_{2})-a_{0}	 
     } 
     { 
b_{0}
     }
\right ]
\end{eqnarray*}
where
$
\log(a_{1})-\Phi^{-1}_{\sev}(p) v_{2} \le   v_{1}   \le \log(b_{1})-\Phi^{-1}_{\sev}(p) v_{2},
v_{2} > 0.$ This is the same 
results as 
(\ref{equation:bearing.cage.prior.mu.sigma})
with $U_{1}=\log(\rvquan_{p})$, $U_{2}=\log(\sigma)$,
$V_{1}=\mu$ and $V_{2}=\sigma$.
\end{enumerate}

%----------------------------------------------------------------------
%----------------------------------------------------------------------
\section{Statistical Error Propagation---The Delta Method}
\label{asection:delta.method}
This section shows how to compute approximate expected values,
variances, and covariances of functions of 
parameter estimators.
Let $g(\thetavec)$ be a real-valued function of
the parameters $\thetavec=(\theta_{1}, \ldots,
\theta_{r})'$ and let $\thetavechat=(\thetahat_{1}, \ldots,
\thetahat_{r})'$ and $g(\thetavechat)$ be
estimates of $\thetavec$ and $g(\thetavec)$, respectively.
The objective is to obtain 
expressions or approximate expressions for $\E \left [
				    g(\thetavechat)
				   \right ]
				$
and				$\var \left [
				    g(\thetavechat)
				   \right ]
				$
as a function of $\E(\thetahat_{i})$, 
$\var(\thetahat_{i})$, and $\cov(\thetahat_{i}, \thetahat_{j})$.

The simplest case is when $g(\thetavechat)$ is a linear
function of the $\thetahat_{i}$, say 
$g(\thetavechat)=a_{0}+\sum_{i=1}^{r} a_{i} \, \thetahat_{i}$, where
the $a_{i}$ are constants.
To facilitate the development express $g(\thetavechat)$ as 
\begin{eqnarray}
g(\thetavechat)&=&a_{0}+\sum_{i=1}^{r} a_{i} \, \thetahat_{i}
=b_{0}+\sum_{i=1}^{r} b_{i} \left [\thetahat_{i} - \E(\thetahat_{i}) \right ]
\label{equation:linear.combination}
\end{eqnarray}
where 
$
b_{0}=a_{0}+\sum_{i=1}^{r} a_{i} \E(\thetahat_{i})
$ and 
$
b_{i}=a_{i}, \,i=1,\ldots,r.
$
In this case, simple computations with expectations
and variances give
\begin{eqnarray*}
\E \left [g(\thetavechat) \right ]&=&b_{0}
\\
\var \left[g(\thetavechat) \right ] &=&
\sum_{i=1}^{r} b_{i}^{2} \, \var(\thetahat_{i}) 
	+ \sum_{i=1}^{r} 
	   \sum_
            {\textstyle {j=1 \atop j\ne i }}^{r} b_{i}\, b_{j}\, \cov(\thetahat_{i}, \thetahat_{j}).
\end{eqnarray*}
When $g(\thetavechat)$ is a smooth nonlinear function of 
the $\thetahat_{i}$s and $g(\thetavechat)$ can be 
approximated by a linear function of
the $\thetahat_{i}$s in the region with 
nonnegligible likelihood,
it is still possible to apply the methodology above.
The general procedure is known as the ``delta method''
or ``statistical error propagation''
and here we describe a simplified version of the methodology.
For a more detailed account, see Hahn
and Shapiro~(1967, page 228) or Stuart and Ord~(1994,
page 350).

When  $g(\thetavec)$ has
continuous second partial derivatives
with respect to $\thetavec$, a
first order (i.e., keeping linear terms only)
Taylor series expansion of
$g(\thetavechat)$ about 
$\muvec=\left [\E(\thetahat_{1}), \ldots, \E(\thetahat_{r}) \right ]$
is given by
\par
\begin{equation} \label{equation:taylor.approximation}
g(\thetavechat) \approx g(\muvec)+
\sum_{i=1}^{r}    \frac{\partial g(\thetavec)}
		    {\partial \theta_{i}}
		  \left [\thetahat_{i}-\E(\thetahat_{i}) \right ]
\end{equation}
where
the partial derivatives  of 
$g(\thetavec)$ with respect to the
$\theta_{i}$ values are evaluated at $\muvec$.

Observe that equation~(\ref{equation:taylor.approximation})
looks like equation~(\ref{equation:linear.combination}) with
\begin{displaymath}
b_{0}=g(\muvec) \quad \mbox{and} \quad
b_{i}=
  \frac{\partial g(\thetavec)}
		    {\partial \theta_{i}},
\quad i=1,\ldots,r.
\end{displaymath}
Consequently,
\begin{eqnarray}
\E \left [g(\thetavechat) \right ] & \approx & g(\muvec)
\nonumber
\\
\var \left[g(\thetavechat) \right ] & \approx &
\sum_{i=1}^{r} 
         \left [
    \frac{\partial g(\thetavec)}
		    {\partial \theta_{i}}
	 \right ]^{2} \, 
\var(\thetahat_{i}) 
\nonumber
\\
& &
	+ \sum_{i=1}^{r} 
	   \sum_
            {\textstyle {j=1 \atop j\ne i }}^{r} 
         \left [
    \frac{\partial g(\thetavec)}
		    {\partial \theta_{i}}
	 \right ] \, 
         \left [
     \frac{\partial g(\thetavec)}
		    {\partial \theta_{j}}
	 \right ] \, 
	 \cov(\thetahat_{i}, \thetahat_{j}).
\label{equation:variance.approximation}
\end{eqnarray}
When the $\thetahat_{i}$s are uncorrelated or
when the covariances $\cov(\thetahat_{i}, \thetahat_{j})$,
$i\ne j$, are small when
compared with  the variances $\var(\thetahat_{i})$, the
last term on the right of equation (\ref{equation:variance.approximation})
is usually omitted from the approximation.


The same ideas apply to vector-valued functions. For example, if
$g_{1}(\thetavec)$ and $g_{2}(\thetavec)$ are two real-valued
functions then
\begin{eqnarray}
\cov \left[g_{1}(\thetavechat), g_{2}(\thetavechat)\right ]  
&\approx&
\sum_{i=1}^{r} 
         \left [
    \frac{\partial g_{1}(\thetavec)}
		    {\partial \theta_{i}}
	 \right ] \, 
	 \left [
     \frac{\partial g_{2}(\thetavec)} 
		    {\partial \theta_{i}} 
	 \right ] 
\var(\thetahat_{i}) 
\nonumber
\\
& &
	+ \sum_{i=1}^{r} 
	   \sum_
            {\textstyle {j=1 \atop j\ne i }}^{r} 
         \left [
    \frac{\partial g_{1}(\thetavec)}
		    {\partial \theta_{i}}
	 \right ] \, 
         \left [
     \frac{\partial g_{2}(\thetavec)}
		    {\partial \theta_{j}}
	 \right ] 
	 \cov(\thetahat_{i}, \thetahat_{j}).
\label{equation:covariance.approximation}
\end{eqnarray}
In general,
for a vector-valued 
function $\gvec(\thetavec)$ of the parameters such
that all the second partial derivatives
with respect to the elements of $\thetavec$ are continuous
\begin{displaymath}
 	\var \left [
             \gvec(\thetavechat)
             \right ] \approx
	\left [\frac{\partial \gvec(\thetavec)}{\partial \thetavec }
 	\right ] \transpose
 	\var(\thetavechat)
	\left [\frac{\partial \gvec(\thetavec)}{\partial \thetavec } \right ]
\end{displaymath}
where $\partial \gvec(\thetavec)/\partial \thetavec 
=[
\partial g_{1}(\thetavec)/\partial \thetavec, 
\partial g_{2}(\thetavec)/\partial \thetavec, \dots
]$ is the 
matrix of gradient vectors  
of first partial derivatives of $\gvec(\thetavec)$
with respect to $\thetavec$ and 
\begin{displaymath}
\var(\thetavechat)=
\left [
	\begin{array}{cccc}
\var(\thetahat_{1}) & \cov(\thetahat_{1},\thetahat_{2})& 
 \cdots &  \cov(\thetahat_{1},\thetahat_{r}) 
\\
&\var(\thetahat_{2}) &  \cdots &  \cov(\thetahat_{2},\thetahat_{r}) 
\\
& & \ddots & \vdots
\\
\mbox{symmetric} & & & \var(\thetahat_{r})
	 \end{array}
\right ]
\end{displaymath}
both evaluated at $\thetavechat$.

The delta method can provide 
good approximations for
$\E[g(\thetavechat)]$ and $\var[g(\thetavechat)]$.
However, as indicated in
more advanced textbooks, one needs to exercise caution in
applying this method because the adequacy of the approximation depends
on the validity of the Taylor approximation and the size of the
remainder in the approximation.
Simulation can be used to check the adequacy of the
approximation.

%----------------------------------------------------------------------

%----------------------------------------------------------------------
\section{Likelihood and Fisher Information Matrices}
\label{asection:likelihood.information.matrix}

Let $\loglike(\thetavec)=\sum_{i=1}^{n}\loglikei(\thetavec)$ denote
the total log likelihood for a specified model and data that will
consist of $n$ independent but not necessarily identically distributed
observations.
Here it is understood that $\loglikei(\thetavec)$ is the
contribution of the $i$th observation to the total log likelihood.
Let $\thetavechat$ be the ML estimator of $\thetavec$
with a sample of size $n$.  
This $\thetavechat$, when it exists, is the value of
$\thetavec$ that maximizes $\loglike(\thetavec)$.
Let $\fishersd(\thetavec)$ denote the
large-sample (or limiting) average amount
of information per observation. Then, in
general
\begin{equation} 
\label{equation:general.information}
     \fishersd(\thetavec)= \lim_{n \rightarrow \infty}
     \left \{ \frac{1}{n}
     \E \left [
    -\frac{\partial ^2 \loglike(\thetavec)}{\partial \thetavec
      \partial \thetavec \transpose}\right ]
     \right \}=
\lim_{n \rightarrow \infty}
\left \{ \frac{1}{n}
\sum^{n}_{i=1} \E\left [-\frac{\partial ^2
\loglikei(\thetavec)}{\partial \thetavec
\partial \thetavec \transpose}\right ]
\right \}
\end{equation}
where the expectation is with respect to the
as of yet unobserved data. 
For large samples, the matrix $I_{\thetavec}=n\fishersd(\thetavec)$
approximately quantifies the amount of
information that we ``expect'' to get from our future data.
Intuitively, this can be seen because larger second derivatives of
$\loglike(\thetavec)$ indicate more curvature in the likelihood, implying that
the likelihood is more concentrated about its maximum.
For a large class of model situations, including
models with independent and identically distributed observations,
$I_{\thetavec}$  simplifies to the 
well-known Fisher information matrix for $\thetavec$
\begin{equation}
\label{equation:special.information}
     I_{\thetavec}= 
     \E \left [
    -\frac{\partial ^2 \loglike(\thetavec)}{\partial \thetavec
      \partial \thetavec \transpose}\right ]
      =
\sum^{n}_{i=1} \E\left [-\frac{\partial ^2
\loglikei(\thetavec)}{\partial \thetavec
\partial \thetavec \transpose}\right ].
\end{equation}
$I_{\thetavec}$ is often known as the Fisher information
or ``expected information'' matrix for $\thetavec$.  
When data are available,
one can compute the ``local'' 
(or ``observed information'' matrix for $\thetavec$)
as
\begin{equation}
\label{equation:observed.information}
     \Ihat_{\thetavec}=
    -\frac{\partial ^2 \loglike(\thetavec)}{\partial \thetavec
      \partial \thetavec \transpose}
=
\sum^{n}_{i=1} \left [-\frac{\partial ^2
\loglike_{i}(\thetavec)}{\partial \thetavec
\partial \thetavec \transpose}\right ]
\end{equation}
where the derivatives are evaluated at $\thetavec=\thetavechat$. 

In Section~\ref{asection:asymptotic.theory.mle}, we explain that
under the standard
regularity conditions,
$n \vcvmat_{\thetavechat}=n  (I_{\thetavec})^{-1}$
is the covariance matrix for the 
asymptotic distribution of 
$\sqrt{n} \,(\thetavechat-\thetavec)$
and an estimate of $I_{\thetavec}$ can be used
to estimate sampling variability in $\thetavechat$.

%----------------------------------------------------------------------
%----------------------------------------------------------------------
\section{Regularity Conditions}
\label{asection:regularity.conditions}
Each technical asymptotic result, such as the asymptotic
distribution of an estimator, or a specific asymptotic property of
an estimator, requires its own set of conditions on the model.  For
example, under a certain set of conditions it is possible to show
that ML estimators are asymptotically normal. With additional
conditions, it can be shown that ML estimators are also
asymptotically efficient. The model, in this case, includes the
underlying probability model for the process (e.g., a failure-time
process) and for the observations process, such as inspections (when
there is not continuous inspection) and characteristics of the
censoring process.  Lehmann~(1983, Chapter 6), for example, gives
precise regularity conditions in the context of ``continuous
inspection.''  Rao~(1973, Section 5e) does the same assuming an
underlying discrete multinomial observation scheme, like that
outlined in Chapter~\ref{chapter:np.models.censoring.likelihood}.
Although censoring is not explicitly treated in either of these
references, the same asymptotic results hold under the standard
kinds of noninformative censoring mechanisms as long as the average
amount of information per sample [elements of
$\fishersd(\thetavec)$] does not decrease substantially as the
sample size increases.  For a modern and rigorous treatment of the
asymptotic properties of ML estimators based on Type~II censored
data see Bhattacharyya~(1985).

For a large set of cases known as ``regular'' cases, there are
useful asymptotic results (see Appendix
Section~\ref{asection:general.theory}) that apply when the pdf of
$\rv$, $f(\realrv; \thetavec),$ (or the pdf of a monotone
transformation of $\rv$) satisfies certain conditions discussed
below.

\subsection{Regularity conditions for location-scale distributions}
When $\grv$ [or a transformation of $\rv$ such as $\grv=\log(\rv)$]
is location-scale with pdf, $f_{\grv}(\grealrv; \thetavec)=
(1/\sigma) \phi[(\grealrv-\mu)/\sigma$, $-\infty<\grealrv<\infty$,
the ``regularity'' conditions can be expressed as
\begin{itemize}
\item 
$-\infty< \mu < \infty$, $\sigma > 0$.
\item 
$ \phi(z) > 0 $ for all $-\infty < z < \infty$.
\item 
The following limits hold
\begin{displaymath}
	 \lim_{z \rightarrow \pm \infty} 
\left [
z^{2} \times
	 \frac{\partial  \phi (z)}
	      {\partial z}
\right ] = 0 .
\end{displaymath}
\item  
The second derivative $\partial ^{2} \phi(z)/\partial z^{2}$ is 
	 continuous.
\item  
The matrix
	 \begin{displaymath}
E \left \{-\frac{\partial ^ 2 \log [\phi(z)]}{\partial \thetavec
 \,
 \partial  \thetavec \transpose}
 \right \}
	 \end{displaymath}
 is positive definite and all its elements are  finite.
\end{itemize}
These conditions are satisfied by the normal (lognormal), $\SEV$
(Weibull), and logistic (loglogistic) distributions. But they are
not satisfied by distributions with a threshold parameter (see
Section~\ref{section:intro.to.threshold.distributions}) because in
these cases the points at which $f_{\grv}(\grealrv; \thetavec)>0$
depend on the values of $\thetavec$.

%----------------------------------------------------------------------

%----------------------------------------------------------------------
\subsection{General regularity conditions}
When $\rv$ (or a monotone transformation of
$\rv$) is not location-scale,
an alternative set of regularity conditions are:
\begin{itemize}
\item 
The points $\realrv$ at which $f(\realrv;\thetavec) > 0$ do not
depend on $\thetavec$.
\item 
The parameters are identifiable in the
sense that $\thetavec_{1} \ne \thetavec_{2}$ 
implies that the probability functions defined by
$f(\realrv;\thetavec_{1})$
and 
$f(\realrv;\thetavec_{2})$ are not identically equal.
\item
The true parameter value $\thetavec$ is in the
interior of the parameter space $\Thetavec$. 
\item 
The
density $f(t; \thetavec)$ has third mixed partial
derivatives with respect to the elements of $\thetavec$ in
a neighborhood of the true $\thetavec$. Each one of  these derivatives
is bounded by a function that 
has finite expectations with respect to $f(\realrv; \thetavec)$.
\item 
For all $\thetavec$ in a neighborhood of the true $\thetavec$, one
can exchange the order of the following two operations:
\begin{itemize}
\item
First and second mixed order of differentiation 
of $\log[f(\realrv; \thetavec)]$ 
with respect to $\thetavec$.
\item
Expectation of $\log[f(\realrv; \thetavec)]$ with
respect to the data from $f(\realrv;\thetavec)$.
\end{itemize}
\item 
The elements of $\fishersd_{\thetavec}$ are finite
      and $\fishersd_{\thetavec}$ is positive definite.
\end{itemize}
These conditions are satisfied, for example, by the $\GAM$, $\GENG$, 
and $\BISA$ distributions of Chapter~\ref{chapter:other.parametric.models}.
%----------------------------------------------------------------------

%----------------------------------------------------------------------
\subsection{Asymptotic theory for nonregular models}
The standard regularity conditions hold for most of the models used in
this book.  One model for which the regularity conditions do not hold
(such models are called ``nonregular'') is the threshold parameter
distributions for which the range over which $f(\realrv;\thetavec) > 0
$ depends on $\thetavec$ (see
Section~\ref{section:intro.to.threshold.distributions}). Having
$\thetavec$ on the boundary of $\Thetavec$ also leads to
``nonregular'' estimation. ML methods are still very useful for
``nonregular'' situations, but the statistical properties and
asymptotic behavior in these cases are more complicated (e.g.,
limiting distributions may depend on $\thetavec$). For such
situations, it is still possible to find useful large-sample
asymptotic results; see, for example, Smith~(1985), and
Woodroofe~(1972, 1974).
%----------------------------------------------------------------------

%----------------------------------------------------------------------
\section{Convergence in Distribution}
\label{asection:convergence.in.distribution}

In this section we use a subscript $n$ to identify
explicitly 
an estimator or quantity with properties that depend on the sample
size $n$. Considering the sequence for increasing
$n$ facilitates the description
of these properties when $n$ gets large (i.e., when
$n\to \infty$).

Convergence in distribution is an important concept for describing the
behavior of estimators in large samples.  For example, one is often
interested in the statistical properties of the ML estimates
$\thetahat_{n}$ of the scalar $\theta $ when the sample
size $n$ increases.  In this case a common approach is to consider the
studentized ratios
\begin{equation} \label{equation:standardized.zratio}
Z_{n}=Z_{n}(\theta)
=\frac{\thetahat_{n}-\theta }
	   {\sehat_{\thetahat_{n}}}, \quad n=2, \ldots
\end{equation}
where $\sehat_{\thetahat_{n}}$ is a consistent
estimator of 
$\se_{\thetahat_{n}}$.  In
general, the exact distribution of $Z_{n}$ is complicated, depending on the
model, actual parameter values, and sample size.  But under the
regularity conditions of
Section~\ref{asection:regularity.conditions},
if $Z_{n}(\theta)$ is evaluated at the true $\theta_{0}$ then
for all $z$
\begin{displaymath}
 \lim_{n \to \infty} F_{Z_{n}}(z)=\Phi_{\nor}(z).
\end{displaymath}
Thus, for finite $n$, one can use the approximation
\begin{eqnarray*}
\Pr \left [
    z_{(\alpha/2)}< Z_{n} \le z_{(1-\alpha/2)}
    \right ]
&=&
F_{Z_{n}}
[
z_{(1-\alpha/2)}
]
-
F_{Z_{n}}
[
z_{(\alpha/2)}
]
\\
  &   \approx &
\Phi_{\nor}\left [z_{(1-\alpha/2)} \right ]-
\Phi_{\nor}\left [z_{(\alpha/2)} \right ]
=1-\alpha.
\end{eqnarray*}
The adequacy of this approximation has to be studied 
(e.g., by simulation) for each
individual problem but in general it works well for a large class of
problems and moderate-to-large sample sizes.

More generally, 
we 
say that the sequence of scalars  $Z_{n}$ converges in
distribution to the continuous random variable $V$ if
 \begin{displaymath}
  \lim_{n \to \infty} F_{Z_{n}}(z)=F_{V}(z)
\quad \mbox{for all $z$}
 \end{displaymath}
where 
$F_{V}(z)$ is the cdf of $V$. 
Thus one can use the
the limiting distribution $F_{V}$ to 
approximate the probabilities for finite $n$
as follows,
\begin{displaymath}
\Pr \left (
    a< Z_{n} \le b 
    \right )=
F_{Z_{n}}(b)-F_{Z_{n}}(a)
     \approx 
F_{V}(b)-F_{V}(a)
\end{displaymath}
where $a, b$ are specified constants. This approximation can be made
as close as desired by taking large values of $n$.  These ideas of
convergence in distribution generalize to vector random variables, see
for example Billingsley~(1986, page~390).

For other examples, let 
$\thetavechat_{n}=(\thetavechat_{1 n}, \thetavechat_{2 n})$ be the
ML estimate of a vector 
$\thetavec =(\thetavec_{1} ,\thetavec_{2} )$ with a sample
of size $n$, 
\begin{itemize}
\item 
 For the profile likelihood of  $\thetavec_{1}$ is
	   \begin{displaymath}
           R_{n}(\thetavec_{1}) = 
        \begin{array}{c} 
         \max  	\\ \thetavec_{2}
	\end{array}
\left[\frac{\like(\thetavec_{1},\thetavec_{2})}
{\like(\thetavechat_{n})}\right].
\end{displaymath} 
The corresponding parameter subset log-likelihood ratio statistic is
$\mbox{LLR}_{n}(\thetavec_{1}) = -2 \log[R_{n}(\thetavec_{1} )]$. This statistic,
when evaluated at the true $\thetavec_{1},$
converges in distribution
to a chi-square distribution with $r_{1}$ degrees of freedom, where
$r_{1}$ is the number of parameters in $\thetavec_{1}$.
\item  
For the parameter subset the ``Wald statistic'' is
\begin{displaymath}
W_{n}(\thetavec_{1})=(\thetavechat_{1n} -\thetavec_{1} ) \transpose
\left (\vcvmathat_{\thetavechat_{1n}} \right ) ^ {-1}
(\thetavechat_{1n} -\thetavec_{1} ).
\end{displaymath}
$W_{n}(\thetavec_{1}),$ evaluated at the true $\thetavec_{1},$
converges in distribution to a chi-square random variable with
$r_{1}$ degrees of freedom.
\end{itemize}



%----------------------------------------------------------------------
%----------------------------------------------------------------------
\section{Outline of General ML Theory}
\label{asection:general.theory}

%----------------------------------------------------------------------
%----------------------------------------------------------------------
\subsection{Asymptotic distribution of ML estimators}
\label{asection:asymptotic.theory.mle}

In this section, we assume that $\thetavechat$ is the
ML estimate of $\thetavec$ based on $n$ observations
and that the 
regularity conditions given in 
Section~\ref{asection:regularity.conditions}
hold. Then it can be shown that 
$\sqrt{n}(\thetavechat-\thetavec)$ converges 
in distribution
to a  multivariate
normal with mean zero and covariance matrix $\fishersd^{-1}(\thetavec)$
defined in~(\ref{equation:general.information}).
In a convenient casual wording, we say that $\thetavechat$
is asymptotically normal with mean $\thetavec$ and
covariance matrix 
$
\vcvmat_{\thetavechat}=I_{\thetavec} ^{-1}
$
where $I_{\thetavec}= n \fishersd(\thetavec)$.
Asymptotic
(large-sample) statistical theory shows that, under the standard
regularity conditions, the elements of $\vcvmat_{\thetavechat}$ are of
the order of $n^{-1}$. This can be seen by noting that
$n\vcvmat_{\thetavechat}$ does not depend on $n$, following from the
definition of $\fishersd(\thetavec)$ in (\ref{equation:general.information}).

Similarly, using the ``observed'' information
it can be shown that $\thetavechat$
is approximately multivariate
normal with mean $\thetavec$ 
 and covariance matrix 
$n \vcvmathat_{\thetavechat}$. This follows from 
convergence in distribution of 
$\sqrt{n}(\thetavechat-\thetavec)$ and the
fact that $n \vcvmathat_{\thetavechat}$ is a 
consistent estimator of $n \vcvmat_{\thetavechat}$.


%----------------------------------------------------------------------
\subsection{Asymptotic covariance matrix for test planning}
\label{asection:asymptotic.covariance}
For an assumed model if there is to be no censoring or truncation,
and if the density approximation
[equation (\ref{equation:density.approximation})] is used for
$\like_{i}(\thetavec)$, then
$\vcvmat_{\thetavechat}=I_{\thetavec}^{-1}$ is a function of the
sample size $n$, the unknown parameters $\thetavec$, and the levels
of the explanatory variables (if any). Otherwise, $I_{\thetavec}$
also depends on the type of censoring, truncation, rounding, etc.,
that will be encountered in the data.  If any of these limitations
on measurement or observation are random, then $I_{\thetavec}$
depends on the distribution(s) of these limitations.  Generally, the
effect of roundoff or binning on the ``correct likelihood'' is not
large (e.g., Meeker 1986). The effect of censoring or truncation
can, however, be substantial. The asymptotic covariance matrix
$\vcvmat_{\thetavechat}$ depends on the underlying model, including
its parameters (but does not depend on data). Thus, for a specified
model, if one has ``planning values'' for $\thetavec$, it is
generally straightforward to evaluate $\vcvmat_{\thetavechat}$
numerically to compute the asymptotic variances of $\thetavechat$
and of smooth functions of $\thetavechat$ (see the details below)
and these asymptotic variances are useful for planning experiments;
see for example Escobar and Meeker~(1994, 1995, 1998d) and
Nelson~(1990a, Chapter 6).

%----------------------------------------------------------------------
%----------------------------------------------------------------------
\subsection{Asymptotic distribution of functions of ML estimators}
\label{asection:asymptotic.theory.fmle}
In general, one is interested in inferences on functions
of $\thetavec$. For example, consider a vector
function $\gvec(\thetavec)$ of the parameters such
that all the second derivatives
with respect to the elements of $\thetavec$ are continuous.
The ML estimator
of $\gvec(\thetavec)$ is $\gvechat=\gvec(\thetavechat)$.
In large
samples, $\gvec(\thetavechat)$
is approximately
normally distributed with mean $\gvec(\thetavec)$
and covariance matrix
\begin{equation} 
\label{equation:gcovariance}
 	\vcvmat_{\gvechat}=
	\left [\frac{\partial \gvec(\thetavec)}{\partial \thetavec }
 	\right ] \transpose
 	\vcvmat_{\thetavechat}
	\left [\frac{\partial \gvec(\thetavec)}{\partial \thetavec } \right ].
\end{equation}
The approximation is based on the assumption that $\gvec(\thetahat)$
is approximately linear in $\thetavec$ in the region near to
$\thetavechat$. The approximation is better in large samples because
then the variation in $\thetavechat$ is smaller and thus the region over
which $\thetavec$ varies is correspondingly smaller. If this region is
small enough, the linear approximation will be adequate.  See
Section~\ref{asection:delta.method} for more details.

For scalar $g$ and $\theta$ the formula simplifies to
\begin{displaymath}
\avar[g(\thetahat)]
=\left [\frac{\partial g(\theta)}{\partial \theta}
 \right ] ^{2}
 \avar(\thetahat)
\end{displaymath}
where $\avar$ is the asymptotic variance function.
For example, if $\theta$ is positive and $g(\theta)$ is the
{\rm logarithmic} function, the asymptotic variance of
$\log(\thetahat)$ is
$\avar[\log(\thetahat)]=\avar(\thetahat)/\theta^{2}$.


%----------------------------------------------------------------------
%----------------------------------------------------------------------
\subsection{Estimating the variance-covariance 
matrix of ML estimates}
\label{asection:observed.information}
Under mild
regularity conditions (see
Section~\ref{asection:regularity.conditions}),
$\vcvmathat_{\thetavechat}=(\Ihat_{\thetavec})^{-1}$
is a consistent estimator of
$\vcvmat_{\thetavechat}$,
where 
$\Ihat_{\thetavec}$ is
defined in~(\ref{equation:observed.information}).
This ``local'' estimate of $\vcvmat_{\thetavechat}$
is obtained by estimating the ``expected''
curvature in (\ref{equation:special.information}) by the ``observed''
curvature in (\ref{equation:observed.information}).  It is possible to
estimate $\vcvmathat_{\thetavechat}$ directly by evaluating 
(\ref{equation:special.information}) at $\thetavec=\thetavechat$,
but this approach is rarely used because it is more complicated and
has no clear advantage.

The ``local''
estimate of the covariance matrix of $\gvechat=\gvec(\thetavechat)$
can be obtained by substituting $\vcvmathat_{\thetavechat}$ for
$\vcvmat_{\thetavechat}$ in (\ref{equation:gcovariance}) giving
\begin{equation} 
\label{equation:gcovariance.est}
 \vcvmathat_{\gvechat}=
\left [\frac{\partial \gvec(\thetavec)}{\partial \thetavec }
 \right ] \transpose
 \vcvmathat_{\thetavechat}
\left [\frac{\partial \gvec(\thetavec)}{\partial \thetavec } \right ].
\end{equation}
where the derivatives are again evaluated at
$\thetavec=\thetavechat$.  For scalar $g$ and $\theta$ the formula
simplifies to
\begin{displaymath}
\varhat[g(\thetahat)]
=\left [\frac{\partial g(\theta)}{\partial \theta}
 \right ] ^{2}
 \vcvmathat_{\thetahat} =\left [\frac{\partial g(\theta)}{\partial \theta}
 \right ] ^{2}
 \varhat(\thetahat).
\end{displaymath}
For example, if $\theta$ is positive and $g(\theta)$ is the
{\rm logarithmic} function, the local estimate of the variance of
$\log(\thetahat)$ is
$\varhat[\log(\thetahat)]=\varhat(\thetahat)/\thetahat^{2}$
and $\sehat[\log(\thetahat)]=\sehat(\thetahat)/\thetahat$.


%-------------------------------------------------------------------
\subsection{Likelihood ratios and profile likelihoods}
\label{section:profile.on.theta}

Assume that we want to estimate $\thetavec_{1}$, from the partition
$\thetavec=(\thetavec_{1},\thetavec_{2})$.  Let $r_{1}$ denote the
length of $\thetavec_{1}$.  The profile likelihood for
$\thetavec_{1}$ is
\begin{equation} 
\label{equation:general.profile.likelihood}
R(\thetavec_{1}) = \begin{array}{c} \max  \\ \thetavec_{2}
\end{array}
\left[\frac{\like(\thetavec_{1},\thetavec_{2})}
{\like(\thetavechat)}\right].
\end{equation}
When the length of $\thetavec_{2}$ is 0 (as in the exponential
distribution in Chapter~\ref{chapter:parametric.ml.one.par} or in
Example~\ref{example:joint.conf.reg.sa}),
(\ref{equation:general.profile.likelihood}) is a relative likelihood
for $\thetavec=\thetavec_{1}$.  Otherwise we have a ``maximized
relative likelihood'' for $\thetavec_{1}$. In either case,
$R(\thetavec_{1})$ is commonly known as a ``profile likelihood''
because it provides a view of the profile of $\like(\thetavec)$ as
viewed along a line that is perpendicular to the axes of
$\thetavec_{1}$.  
\begin{itemize}
\item
When $\thetavec_{1}$ is of length 1, $R(\thetavec_{1})$ is a curve
projected onto a plane.
\item
When $\thetavec_{1}$ is of length 2 or more, $R(\thetavec_{1})$
is a surface projected onto a three-dimensional hyperplane.
\end{itemize}
In either case the projection is in a direction perpendicular to the
coordinate axes for $\thetavec_{1}$.  When $\thetavec_{1}$ is of
length 1 or 2, it is useful to display $R(\thetavec_{1})$ graphically.


Asymptotically, $\mbox{LLR}_{n}(\thetavec_{1}) = -2
\log[R(\thetavec_{1})]$ when evaluated at the true $\thetavec_{1}$,
has a chi-square distribution with $r_{1}$ degrees of freedom. To
do a likelihood ratio significance test, we would reject the null
hypothesis that $\thetavec=\thetavec_{0}$, at the $\alpha$ level of
significance, if
\begin{displaymath}
\mbox{LLR}_{n}(\thetavec_{1}) = 
	-2 \log[R(\thetavec_{0})] > \chisquare_{(1-\alpha;r_{1})}.
\end{displaymath}


%----------------------------------------------------------------------
%----------------------------------------------------------------------
\subsection{Approximate likelihood-ratio-based confidence regions
or confidence intervals for
the model parameters}
\label{section:like.con.regions}

An approximate $100(1-\alpha)\%$ likelihood-ratio-based confidence
region for $\thetavec_{1}$ is the set of all values of
$\thetavec_{1}$ such that $\mbox{LLR}_{n}(\thetavec_{1}) = -2
\log[R(\thetavec_{1})] < \chi^{2}_{(1-\alpha;r_{1})}$, or
equivalently, $R(\thetavec _{1}) >
\exp \left [-\chi^{2}_{(1-\alpha;r_{1})}/2 \right ]$.
Here $\thetavec _{1}$ could be the full parameter vector, a single
element of $\thetavec$, or some other subset of $\thetavec$.  If one
is interested in a scalar function $g(\thetavec)$, these same ideas
can be applied after a reparameterization such that $g(\thetavec)$
is one of the parameters.  Simulation studies for different
applications and models (e.g., Ostrouchov and Meeker~1988,
Meeker~1987, Vander Wiel and Meeker~1990, and Jeng and Meeker~1998)
have shown that in terms of closeness to the nominal confidence
level, the likelihood-based intervals have important advantages over
the standard normal-approximation intervals (discussed in
Section~\ref{asection:ci.wald}), especially when there is only a
small number of failures in the data.  Specifically, in repeated
sampling, normal-approximation intervals tend to have actual
confidence levels that are smaller than the nominal levels.
Likelihood-ratio-based intervals tend to have confidence levels that
are much closer to the nominal.  Also see Meeker and Escobar~(1995).


%----------------------------------------------------------------------
%----------------------------------------------------------------------
\subsection{Approximate confidence regions and intervals based on asymptotic
normality of ML estimators}

\label{asection:ci.wald}

The large-sample normal approximation for the distribution of ML
estimators can be used to compute approximate confidence intervals
(regions) for scalar (vector) functions of $\thetavec$.  In
particular, an approximate $100(1-\alpha)$\% confidence region for
$\thetavec$ is the set of all values of $\thetavec$ in the ellipsoid
\begin{equation}
\label{equation:wald.region}
(\thetavechat -\thetavec) \transpose
\left (\vcvmathat_{\thetavechat} \right ) ^ {-1}
(\thetavechat -\thetavec) \leq \chi^{2}_{(1-\alpha;r)}
\end{equation}
where $r$ is the length of $\thetavec$.  This is sometimes known as
``Wald's method,'' but we will refer to it as the
``normal-approximation'' method. This confidence region (or
interval) is based on the distributional result that,
asymptotically, when evaluated at the true $\thetavec$, the ``Wald
statistic''
\begin{displaymath}
W(\thetavec)=(\thetavechat -\thetavec ) \transpose
\left (\vcvmathat_{\thetavechat} \right ) ^ {-1}
(\thetavechat -\thetavec )
\end{displaymath}
has a chi-square distribution 
with $r$ degrees of freedom.


More generally, let $\gvec(\thetavec)$ be a vector function
of $\thetavec$. An approximate $100(1-\alpha)\%$
normal-approximation confidence region for a $r_{1}$-dimensional
subset $\gvec_{1}=\gvec_{1}(\thetavec)$, from the partition
$\gvec(\thetavec)= \left [\gvec_{1}(\thetavec),
\gvec_{2}(\thetavec) \right ]$, is
the set of all the $\gvec_{1}$'s in the
ellipsoid
\begin{displaymath}
(\gvechat_{1} -\gvec_{1}) \transpose
\left (\vcvmathat_{\gvechat_{1}} \right ) ^ {-1}
(\gvechat_{1} -\gvec_{1}) \leq \chi^{2}_{(1-\alpha;r_{1})}
\end{displaymath}
where $\gvechat_{1}=\gvec_{1}(\thetavechat)$ is the ML estimator of
$\gvec_{1}(\thetavec)$ and $\vcvmathat_{\gvechat_{1}}$ is the local
estimate of the covariance matrix of $\gvechat_{1}$.  The estimate
$\vcvmathat_{\gvechat_{1}}$ can be obtained from the local estimate
of $ \vcvmat_{\gvechat}$ in
equation~(\ref{equation:gcovariance.est}).  This confidence region
(or interval) is based on the distributional result that the ``Wald
subset statistic,'' when evaluated at the true $\gvec_{1}$
\begin{displaymath}
W(\gvec_{1} )=(\gvechat_{1} -\gvec_{1} ) \transpose
\left (\vcvmathat_{\gvechat_{1}} \right ) ^ {-1}
(\gvechat_{1} -\gvec_{1} ) 
\end{displaymath}
has, asymptotically, a
chi-square distribution with $r_{1}$ degrees of freedom.
As shown in Meeker and Escobar~(1995), this 
normal-approximation confidence region (or interval)
can be viewed as a quadratic approximation
for the log profile likelihood of $\gvec_{1}(\thetavec)$ at
$\gvechat_{1}$.

When $r_{1}=1$, $g_{1} =\gvec_{1}(\thetavec)$
is a scalar function of
$\thetavec$,  an approximate
$100(1-\alpha)$\% normal-approximation interval is
obtained from the familiar formula
\begin{equation}
\label{equation:appendix.ci.for.function}
[\undertilde{g}_{}{}_{1}, \quad \tilde{g}_{1}]= \ghat_{1} \pm
 \norquan_{(1-\alpha/2)} \sehat_{\ghat_{1}}
\end{equation}
where $\sehat_{\ghat_{1}}=\sqrt{\widehat{\var}[g_{1}(\thetavechat)]}$
is the local estimate
for the standard error of $\ghat_{1}$ and $\norquan_{(1-\alpha/2)}$
is the $1-\alpha/2$ quantile of the standard normal distribution.
